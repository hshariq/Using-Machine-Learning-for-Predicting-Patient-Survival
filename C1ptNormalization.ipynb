{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "Train = pd.read_csv(\"Data/train.csv\")\n",
    "Test = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train.drop('gender', axis=1, inplace=True)\n",
    "# Test.drop('gender', axis=1, inplace=True)\n",
    "# Train.drop('apache_3j_bodysystem', axis=1, inplace=True)\n",
    "# Test.drop('apache_3j_bodysystem', axis=1, inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#normalise Train['pre_icu_los_days']\n",
    "Train['pre_icu_los_days'] = np.log1p(Train['pre_icu_los_days'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "\n",
    "#normalise Train['pre_icu_los_days']\n",
    "Test['pre_icu_los_days'] = np.log1p(Test['pre_icu_los_days'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#simialrly normalise apache_2_diagnosis\n",
    "Train['apache_2_diagnosis'] = np.log1p(Train['apache_2_diagnosis'])\n",
    "Test['apache_2_diagnosis'] = np.log1p(Test['apache_2_diagnosis'])\n",
    "#do for apache_3j_diagnosis as well for both train and test\n",
    "Train['apache_3j_diagnosis'] = np.log1p(Train['apache_3j_diagnosis'])\n",
    "#do for test as well\n",
    "Test['apache_3j_diagnosis'] = np.log1p(Test['apache_3j_diagnosis'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for resprate_apache as well\n",
    "Train['d1_resprate_max'] = np.log1p(Train['d1_resprate_max'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for test as well\n",
    "Test['d1_resprate_max'] = np.log1p(Test['d1_resprate_max'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for temp_apache as well\n",
    "Train['temp_apache'] = np.log1p(Train['temp_apache'])\n",
    "#do for test as well\n",
    "Test['temp_apache'] = np.log1p(Test['temp_apache'])\n",
    "#do foor d1_resprate_max as well\n",
    "Train['d1_resprate_max'] = np.log1p(Train['d1_resprate_max'])\n",
    "#do for test as well\n",
    "Test['d1_resprate_max'] = np.log1p(Test['d1_resprate_max'])\n",
    "#do for d1_temp_min\n",
    "Train['d1_temp_min'] = np.log1p(Train['d1_temp_min'])\n",
    "#do for test as well\n",
    "Test['d1_temp_min'] = np.log1p(Test['d1_temp_min'])\n",
    "#do foe h1_spo2_max\n",
    "Train['h1_spo2_max'] = np.log1p(Train['h1_spo2_max'])\n",
    "#do for test as well\n",
    "Test['h1_spo2_max'] = np.log1p(Test['h1_spo2_max'])\n",
    "#do for h1_spo2_min\n",
    "Train['h1_spo2_min'] = np.log1p(Train['h1_spo2_min'])\n",
    "#do for test as well\n",
    "Test['h1_spo2_min'] = np.log1p(Test['h1_spo2_min'])\n",
    "#do for d1_glucose_max\n",
    "Train['d1_glucose_max'] = np.log1p(Train['d1_glucose_max'])\n",
    "#do for test as well\n",
    "Test['d1_glucose_max'] = np.log1p(Test['d1_glucose_max'])\n",
    "#since all these r heavily skewed andaffected by the outliers we will fill them using median imputation\n",
    "\n",
    "# fill null values with median for temp_apache\n",
    "Train['temp_apache'].fillna(Train['temp_apache'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for d1_potassium_max\n",
    "Train['d1_potassium_max'].fillna(Train['d1_potassium_max'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_hospital_death_prob\n",
    "Train['apache_4a_hospital_death_prob'].fillna(Train['apache_4a_hospital_death_prob'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_icu_death_prob\n",
    "Train['apache_4a_icu_death_prob'].fillna(Train['apache_4a_icu_death_prob'].median(), inplace=True)\n",
    "#since all these r heavily skewed andaffected by the outliers we will fill them using median imputation\n",
    "\n",
    "Test['temp_apache'].fillna(Test['temp_apache'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for d1_potassium_max\n",
    "Test['d1_potassium_max'].fillna(Test['d1_potassium_max'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_hospital_death_prob\n",
    "Test['apache_4a_hospital_death_prob'].fillna(Test['apache_4a_hospital_death_prob'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_icu_death_prob\n",
    "Test['apache_4a_icu_death_prob'].fillna(Test['apache_4a_icu_death_prob'].median(), inplace=True)\n",
    "\n",
    "# group the dataframe by apache_2_bodysystem and calculate the mean age for each group\n",
    "mean_age_by_bodysystem = Train.groupby('apache_2_bodysystem')['age'].mean()\n",
    "\n",
    "# define a function that takes a row of the dataframe as input and returns the mean age of the corresponding apache_2_bodysystem\n",
    "def fill_age(row):\n",
    "    if pd.isnull(row['age']):\n",
    "        if pd.isnull(row['apache_2_bodysystem']):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return mean_age_by_bodysystem[row['apache_2_bodysystem']]\n",
    "    else:\n",
    "        return row['age']\n",
    "\n",
    "# apply the function to each row of the dataframe and fill the missing age values with the corresponding mean age\n",
    "Train['age'] = Train.apply(fill_age, axis=1)\n",
    "\n",
    "# group the dataframe by apache_2_bodysystem and calculate the mean age for each group\n",
    "mean_age_by_bodysystem = Test.groupby('apache_2_bodysystem')['age'].mean()\n",
    "\n",
    "# define a function that takes a row of the dataframe as input and returns the mean age of the corresponding apache_2_bodysystem\n",
    "def fill_age(row):\n",
    "    if pd.isnull(row['age']):\n",
    "        if pd.isnull(row['apache_2_bodysystem']):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return mean_age_by_bodysystem[row['apache_2_bodysystem']]\n",
    "    else:\n",
    "        return row['age']\n",
    "\n",
    "# apply the function to each row of the dataframe and fill the missing age values with the corresponding mean age\n",
    "Test['age'] = Test.apply(fill_age, axis=1)\n",
    "\n",
    "#for all binary columns we will apply mode imputation for missing values\n",
    "#first we will create a list of all binary columns\n",
    "binary_colsTest = ['elective_surgery', 'apache_post_operative', 'gcs_unable_apache', 'intubated_apache', 'ventilated_apache','immunosuppression', 'solid_tumor_with_metastasis']\n",
    "\n",
    "binary_colsTrain = ['elective_surgery', 'apache_post_operative', 'gcs_unable_apache', 'intubated_apache', 'ventilated_apache','immunosuppression', 'solid_tumor_with_metastasis','hospital_death']\n",
    "#now we will apply mode imputation on these columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "binary_colsTest = [col for col in Train.columns if Train[col].dtype == 'object' or col in binary_colsTest]\n",
    "binary_colsTrain = [col for col in Test.columns if Test[col].dtype == 'object' or col in binary_colsTrain]\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "Train[binary_colsTrain] = imputer.fit_transform(Train[binary_colsTrain])\n",
    "Test[binary_colsTest] = imputer.fit_transform(Test[binary_colsTest])\n",
    "\n",
    "numeric_cols = [col for col in Train.select_dtypes(include=[np.number]).columns if col not in binary_colsTrain]\n",
    "numeric_colsTest = [col for col in Test.select_dtypes(include=[np.number]).columns if col not in binary_colsTrain]\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# create an instance of KNNImputer with k=5\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# fill missing values in Train dataframe\n",
    "Train[numeric_cols] = imputer.fit_transform(Train[numeric_cols])\n",
    "\n",
    "# fill missing values in Test dataframe\n",
    "Test[numeric_colsTest] = imputer.fit_transform(Test[numeric_colsTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehot= pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehot= pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehot= pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehot= pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehot= pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehot= pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehot= pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehotTest= pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehotTest= pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehotTest= pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehotTest= pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehotTest= pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehotTest= pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_2884\\2793514417.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  onehotTest= pd.get_dummies(Test)\n"
     ]
    }
   ],
   "source": [
    "onehot= pd.get_dummies(Train)\n",
    "onehotTest= pd.get_dummies(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['ethnicity', 'gender', 'icu_admit_source', 'icu_stay_type', 'icu_type', 'apache_3j_bodysystem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do label encoding on Train and test\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in columns:\n",
    "    Train[col] = le.fit_transform(Train[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply label encoding on all catoegircal columns\n",
    "le = LabelEncoder()\n",
    "for col in columns:\n",
    "    Test[col] = le.fit_transform(Test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop apache_2_bodysystem\n",
    "Train.drop('apache_3j_bodysystem', axis=1, inplace=True)\n",
    "Test.drop('apache_3j_bodysystem', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>icu_id</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>icu_stay_type</th>\n",
       "      <th>icu_type</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>h1_sysbp_min</th>\n",
       "      <th>h1_sysbp_noninvasive_max</th>\n",
       "      <th>h1_sysbp_noninvasive_min</th>\n",
       "      <th>d1_glucose_max</th>\n",
       "      <th>d1_potassium_max</th>\n",
       "      <th>apache_4a_hospital_death_prob</th>\n",
       "      <th>apache_4a_icu_death_prob</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Floor</td>\n",
       "      <td>transfer</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4.985586</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>African American</td>\n",
       "      <td>M</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>5.811141</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Floor</td>\n",
       "      <td>admit</td>\n",
       "      <td>MICU</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>162.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>5.081404</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Neurologic</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.556828</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>admit</td>\n",
       "      <td>CSICU</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>4.709530</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID  hospital_id  icu_id         ethnicity gender  \\\n",
       "0       1.0        126.0  1931.0         Caucasian      M   \n",
       "1       2.0        112.0  1544.0  African American      M   \n",
       "2       3.0        153.0  1517.0         Caucasian      M   \n",
       "3       4.0        109.0  1811.0         Caucasian      M   \n",
       "4       5.0        287.0  1845.0         Caucasian      F   \n",
       "\n",
       "       icu_admit_source icu_stay_type      icu_type apache_2_bodysystem   age  \\\n",
       "0                 Floor      transfer  Med-Surg ICU           Metabolic  28.0   \n",
       "1  Accident & Emergency         admit  Med-Surg ICU      Cardiovascular  69.0   \n",
       "2                 Floor         admit          MICU         Respiratory  84.0   \n",
       "3  Accident & Emergency         admit  Med-Surg ICU          Neurologic  59.0   \n",
       "4  Accident & Emergency         admit         CSICU      Cardiovascular  85.0   \n",
       "\n",
       "   ... h1_sysbp_min  h1_sysbp_noninvasive_max  h1_sysbp_noninvasive_min  \\\n",
       "0  ...         86.0                      93.0                      86.0   \n",
       "1  ...         95.0                      95.0                      95.0   \n",
       "2  ...        162.0                     174.0                     162.0   \n",
       "3  ...        140.0                     163.0                     140.0   \n",
       "4  ...        119.0                     119.0                     119.0   \n",
       "\n",
       "   d1_glucose_max d1_potassium_max  apache_4a_hospital_death_prob  \\\n",
       "0        4.985586              4.1                           0.01   \n",
       "1        5.811141              3.7                           0.05   \n",
       "2        5.081404              4.2                           0.38   \n",
       "3        5.556828              3.8                           0.12   \n",
       "4        4.709530              3.9                           0.15   \n",
       "\n",
       "   apache_4a_icu_death_prob immunosuppression  solid_tumor_with_metastasis  \\\n",
       "0                      0.00                 0                            0   \n",
       "1                      0.02                 0                            0   \n",
       "2                      0.15                 0                            0   \n",
       "3                      0.06                 0                            0   \n",
       "4                      0.07                 0                            0   \n",
       "\n",
       "   hospital_death  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xlabel=Train.loc[:, Train.columns != 'hospital_death']  \n",
    "ylabel=Train['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=onehot.loc[:, onehot.columns != 'hospital_death']\n",
    "y=onehot['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, train_test_split, validation_curve\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xlabel, ylabel, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost  :  0.8797615050245421\n",
      "Total time CB:  303.1622004508972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "gb = GradientBoostingClassifier(max_depth=5,n_estimators=300)\n",
    "#record the start time\n",
    "start_time = time.time()\n",
    "gb.fit(X_train,y_train)\n",
    "md_probs = gb.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Cat Boost\" , \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time CB: \", total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost  :  0.8792644650441485\n",
      "Total time CB:  97.90764904022217\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ab = AdaBoostClassifier(n_estimators=350, learning_rate=0.1)\n",
    "ab.fit(X_train,y_train)\n",
    "md_probs = ab.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Cat Boost\" , \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time CB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_pred = ab.predict_proba(onehotTest)\n",
    "hospital_death = y_new_pred[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost  :  0.8867494831438578\n",
      "Total time AB:  7591.1168377399445\n"
     ]
    }
   ],
   "source": [
    "#record the start time\n",
    "start_time = time.time()\n",
    "nb_c = CatBoostClassifier()\n",
    "bg_c = BaggingClassifier(base_estimator=nb_c, n_estimators=300, n_jobs=-1)\n",
    "bg_c.fit(X_train,y_train)\n",
    "md_probs = bg_c.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Cat Boost\" , \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "#calculate the total time\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time AB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost  :  0.8853803613386769\n",
      "Total time AB:  12665.106829166412\n"
     ]
    }
   ],
   "source": [
    "#record the start time\n",
    "start_time = time.time()\n",
    "nb_c = CatBoostClassifier(**modelCAT.best_params_, learning_rate=0.1)\n",
    "bg_c = BaggingClassifier(base_estimator=nb_c, n_estimators=300, n_jobs=-1)\n",
    "bg_c.fit(X_train,y_train)\n",
    "md_probs = bg_c.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Cat Boost\" , \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "#calculate the total time\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time AB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_predBAG = bg_c.predict_proba(onehotTest)\n",
    "hospital_death = y_new_predBAG[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsBGC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsXGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use xgboost\n",
    "xgb_model = xgb.XGBClassifier(learning_rate =0.1,\n",
    "n_estimators=500,\n",
    "max_depth=5,\n",
    "min_child_weight=1,\n",
    "gamma=0,\n",
    "subsample=0.8,\n",
    "colsample_bytree=0.8,\n",
    "objective= 'binary:logistic',\n",
    "nthread=4,\n",
    "scale_pos_weight=1,\n",
    "seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\core.py:160: UserWarning: [20:44:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"boosting_type\", \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.8, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=0, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.1...\n",
       "                                        &#x27;colsample_bytree&#x27;: [0.4, 0.5, 0.6, 0.7,\n",
       "                                                             0.8, 0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.25, 0.5, 1.0],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19, 21, 23],\n",
       "                                        &#x27;min_child_weight&#x27;: [0.5, 1.0, 3.0, 5.0,\n",
       "                                                             7.0, 10.0],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 500, 800, 1100,\n",
       "                                                         1400, 1700, 2000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.1, 1.0, 5.0, 10.0, 50.0,\n",
       "                                                      100.0],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.1, 1.0, 5.0, 10.0,\n",
       "                                                       50.0, 100.0],\n",
       "                                        &#x27;silent&#x27;: [False],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.8, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=0, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.1...\n",
       "                                        &#x27;colsample_bytree&#x27;: [0.4, 0.5, 0.6, 0.7,\n",
       "                                                             0.8, 0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.25, 0.5, 1.0],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19, 21, 23],\n",
       "                                        &#x27;min_child_weight&#x27;: [0.5, 1.0, 3.0, 5.0,\n",
       "                                                             7.0, 10.0],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 500, 800, 1100,\n",
       "                                                         1400, 1700, 2000],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.1, 1.0, 5.0, 10.0, 50.0,\n",
       "                                                      100.0],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.1, 1.0, 5.0, 10.0,\n",
       "                                                       50.0, 100.0],\n",
       "                                        &#x27;silent&#x27;: [False],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.8, device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=0, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.1...\n",
       "                                        'colsample_bytree': [0.4, 0.5, 0.6, 0.7,\n",
       "                                                             0.8, 0.9, 1.0],\n",
       "                                        'gamma': [0, 0.25, 0.5, 1.0],\n",
       "                                        'max_depth': [3, 5, 7, 9, 11, 13, 15,\n",
       "                                                      17, 19, 21, 23],\n",
       "                                        'min_child_weight': [0.5, 1.0, 3.0, 5.0,\n",
       "                                                             7.0, 10.0],\n",
       "                                        'n_estimators': [200, 500, 800, 1100,\n",
       "                                                         1400, 1700, 2000],\n",
       "                                        'reg_alpha': [0.1, 1.0, 5.0, 10.0, 50.0,\n",
       "                                                      100.0],\n",
       "                                        'reg_lambda': [0.1, 1.0, 5.0, 10.0,\n",
       "                                                       50.0, 100.0],\n",
       "                                        'silent': [False],\n",
       "                                        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define range of the parameters for optimization using RandomizedSearchCV\n",
    "optimization_dict = {\"boosting_type\": ['gbdt','dart'],\n",
    "\"n_estimators\"     : [200,500,800,1100,1400,1700,2000],\n",
    "\"max_depth\"        : [3,5,7,9,11,13,15,17,19,21,23],\n",
    "'silent': [False],\n",
    "'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "'gamma': [0, 0.25, 0.5, 1.0],\n",
    "'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "'reg_alpha': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0]}\n",
    "# Define RandomizedSearchCV\n",
    "model = RandomizedSearchCV(xgb_model, optimization_dict, \n",
    "                     scoring='roc_auc', n_iter=10, verbose=1,n_jobs=4, cv=2)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'subsample': 0.8,\n",
       "  'silent': False,\n",
       "  'reg_lambda': 50.0,\n",
       "  'reg_alpha': 0.1,\n",
       "  'n_estimators': 800,\n",
       "  'min_child_weight': 0.5,\n",
       "  'max_depth': 3,\n",
       "  'gamma': 0,\n",
       "  'colsample_bytree': 0.9,\n",
       "  'colsample_bylevel': 0.6,\n",
       "  'boosting_type': 'gbdt'},\n",
       " 0.8737908036111606)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_, model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(**model.best_params_,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " random_state=1, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xgboost\\core.py:160: UserWarning: [20:46:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"boosting_type\", \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, boosting_type=&#x27;gbdt&#x27;,\n",
       "              callbacks=None, colsample_bylevel=0.6, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=0.5, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None, nthread=4, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, boosting_type=&#x27;gbdt&#x27;,\n",
       "              callbacks=None, colsample_bylevel=0.6, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=0.5, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None, nthread=4, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, boosting_type='gbdt',\n",
       "              callbacks=None, colsample_bylevel=0.6, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=0.5, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=800, n_jobs=None, nthread=4, ...)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost  :  0.8859352138685933\n",
      "Total time XGB:  0.13788771629333496\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#fit xgb_model\n",
    "# model.fit(X_train,y_train)\n",
    "md_probs = model.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"XG Boost\", \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "#calculate the total time\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time XGB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hamza\\Documents\\7th Sem\\IDM\\Challenge 1\\C1ptNormalization.ipynb Cell 33\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m xgb_clf \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRFClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m,max_depth\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m xgb_clf\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m md_probs \u001b[39m=\u001b[39m xgb_clf\u001b[39m.\u001b[39mpredict_proba(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# xgbrf classifier\n",
    "import time\n",
    "start_time = time.time()\n",
    "xgb_clf = xgb.XGBRFClassifier(n_estimators=300,max_depth=6, random_state=1, learning_rate=0.1)\n",
    "xgb_clf.fit(X_train,y_train)\n",
    "md_probs = xgb_clf.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"XG Boost\", \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "#calculate the total time\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time XGB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_pred = model.predict_proba(onehotTest)\n",
    "hospital_death = y_new_pred[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3057, number of negative: 31943\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4089\n",
      "[LightGBM] [Info] Number of data points in the train set: 35000, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.087343 -> initscore=-2.346519\n",
      "[LightGBM] [Info] Start training from score -2.346519\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LG Boost  :  0.8805180186523998\n",
      "Total time LGB:  1.4904475212097168\n"
     ]
    }
   ],
   "source": [
    "#use lgboost\n",
    "import time\n",
    "lgb_model = lgb.LGBMClassifier(max_depth=5, n_estimators=100, learning_rate=0.1, num_leaves=100)\n",
    "start_time = time.time()\n",
    "#fit xgb_model\n",
    "lgb_model.fit(X_train_filtered,y_train)\n",
    "md_probs = lgb_model.predict_proba(X_test_filtered)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"LG Boost\", \" : \", md_auc)\n",
    "#record the end time|\n",
    "end_time = time.time()\n",
    "#calculate the total time\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time LGB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 102)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 30)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only get features that have feautre importnace score of more than 100\n",
    "from lightgbm import plot_importance \n",
    "\n",
    "plot_importance(lgb_model, figsize=(10, 9))\n",
    "#only get features that have feautre importnace score of more than 100\n",
    "\n",
    "important_features = X_train.columns[lgb_model.feature_importances_ > 140]\n",
    "\n",
    "X_train_filtered = X_train.loc[:, important_features]\n",
    "X_test_filtered = X_test.loc[:, important_features]\n",
    "X_train_filtered = X_train[important_features]\n",
    "X_test_filtered = X_test[important_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from one hot test get only important features\n",
    "onehotTest_filtered = onehotTest.loc[:, important_features]\n",
    "onehotTest_filtered = onehotTest[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_pred = lgb_model.predict_proba(onehotTest_filtered)\n",
    "hospital_death = y_new_pred[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC:  0.87985320904318\n",
      "Standard deviation of AUC:  0.0013064862713426028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Define the number of iterations for bootstrapping\n",
    "n_iterations = 100\n",
    "\n",
    "# Define a list to store the AUC values obtained from each iteration\n",
    "auc_values = []\n",
    "\n",
    "# Define the CatBoostClassifier model\n",
    "cbBOOTS = CatBoostClassifier(iterations=350, depth=5, learning_rate=0.1, loss_function='Logloss', verbose=False)\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(n_iterations):\n",
    "    # Sample the data with replacement\n",
    "    X_train_resampled, y_train_resampled = resample(X_train, y_train, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit the model on the resampled data\n",
    "    cbBOOTS.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Calculate the AUC on the test set\n",
    "    md_probs = cbBOOTS.predict_proba(X_test)\n",
    "    md_probs = md_probs[:,1]\n",
    "    md_auc = roc_auc_score(y_test, md_probs)\n",
    "    \n",
    "    # Store the AUC value in the list\n",
    "    auc_values.append(md_auc)\n",
    "\n",
    "# Calculate the mean and standard deviation of the AUC values\n",
    "mean_auc = np.mean(auc_values)\n",
    "std_auc = np.std(auc_values)\n",
    "\n",
    "# Print the mean and standard deviation of the AUC values\n",
    "print(\"Mean AUC: \", mean_auc)\n",
    "print(\"Standard deviation of AUC: \", std_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of iterations for bootstrapping\n",
    "n_iterations = 100\n",
    "\n",
    "# Define the CatBoostClassifier model\n",
    "cbBOOTS = CatBoostClassifier(iterations=350, depth=5, learning_rate=0.1, loss_function='Logloss', verbose=False)\n",
    "\n",
    "# Initialize an empty list to store the models\n",
    "models = []\n",
    "\n",
    "# Perform bootstrapping\n",
    "for i in range(n_iterations):\n",
    "    # Sample the data with replacement\n",
    "    X_train_resampled, y_train_resampled = resample(X_train, y_train, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit the model on the resampled data\n",
    "    cbBOOTS.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Store the fitted model\n",
    "    models.append(cbBOOTS)\n",
    "\n",
    "# Now use the models to predict on test data\n",
    "predictions = []\n",
    "for model in models:\n",
    "    y_pred = model.predict_proba(onehotTest)\n",
    "    predictions.append(y_pred[:, 1])\n",
    "\n",
    "# Average the predictions\n",
    "hospital_death = np.mean(predictions, axis=0)\n",
    "\n",
    "# Now 'hospital_death' contains the averaged predictions from all the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 102)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest  :  0.8437818989704075\n"
     ]
    }
   ],
   "source": [
    "# apply pca on random forest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pca = PCA(n_components=95)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "X_reduced.shape\n",
    "X_reducedPD=pd.DataFrame(X_reduced)\n",
    "X_reducedPD.head()\n",
    "\n",
    "# now use this to train and predict\n",
    "rfPCA = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=1)\n",
    "rfPCA.fit(X_reduced,y_train)\n",
    "md_probs = rfPCA.predict_proba(X_test_reduced)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Random Forest\" , \" : \", md_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now use the best model to predict on test data\n",
    "y_new_pred = cbBOOTS.predict_proba(onehotTest)\n",
    "hospital_death = y_new_pred[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(iterations=350, depth=15, learning_rate=0.1, loss_function='Logloss', verbose=False)\n",
    "#record the start time\n",
    "start_time = time.time()\n",
    "cb.fit(X_train,y_train)\n",
    "md_probs = cb.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Cat Boost\", \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time CB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define range of the parameters for optimization using RandomizedSearchCV\n",
    "optimization_dict = {\n",
    "    'depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "    'iterations': [200, 500, 800, 1100, 1400, 1700, 2000],\n",
    "    'border_count': [32, 64, 96, 128, 160, 192, 224, 256],\n",
    "    'bagging_temperature': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'random_strength': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'leaf_estimation_iterations': [1, 5, 10, 15, 20, 25, 30],\n",
    "    'leaf_estimation_method': ['Newton', 'Gradient'],\n",
    "    'boosting_type': ['Plain', 'Ordered', 'Randomized'],\n",
    "    'bootstrap_type': ['Bayesian', 'Bernoulli', 'MVS', 'Poisson'],\n",
    "    'fold_permutation_block': [1, 2, 3, 4, 5],\n",
    "    'od_type': ['IncToDec', 'Iter'],\n",
    "    'task_type': ['CPU', 'GPU']\n",
    "}\n",
    "\n",
    "# Define RandomizedSearchCV\n",
    "modelCAT = RandomizedSearchCV(\n",
    "    CatBoostClassifier(),\n",
    "    optimization_dict,\n",
    "    scoring='roc_auc',\n",
    "    n_iter=10,\n",
    "    verbose=1,\n",
    "    n_jobs=4,\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "modelCAT.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'task_type': 'CPU',\n",
       "  'random_strength': 7,\n",
       "  'od_type': 'IncToDec',\n",
       "  'leaf_estimation_method': 'Gradient',\n",
       "  'leaf_estimation_iterations': 25,\n",
       "  'l2_leaf_reg': 1,\n",
       "  'iterations': 1100,\n",
       "  'fold_permutation_block': 1,\n",
       "  'depth': 7,\n",
       "  'border_count': 96,\n",
       "  'bootstrap_type': 'MVS',\n",
       "  'boosting_type': 'Plain',\n",
       "  'bagging_temperature': 1},\n",
       " 0.8770271290138034)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelCAT.best_params_, modelCAT.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6039185\ttotal: 156ms\tremaining: 2m 50s\n",
      "1:\tlearn: 0.5258330\ttotal: 329ms\tremaining: 3m\n",
      "2:\tlearn: 0.4652530\ttotal: 458ms\tremaining: 2m 47s\n",
      "3:\tlearn: 0.4228287\ttotal: 551ms\tremaining: 2m 31s\n",
      "4:\tlearn: 0.3850007\ttotal: 635ms\tremaining: 2m 19s\n",
      "5:\tlearn: 0.3566655\ttotal: 727ms\tremaining: 2m 12s\n",
      "6:\tlearn: 0.3324807\ttotal: 852ms\tremaining: 2m 13s\n",
      "7:\tlearn: 0.3158288\ttotal: 952ms\tremaining: 2m 9s\n",
      "8:\tlearn: 0.3003778\ttotal: 1.04s\tremaining: 2m 5s\n",
      "9:\tlearn: 0.2865821\ttotal: 1.13s\tremaining: 2m 2s\n",
      "10:\tlearn: 0.2770358\ttotal: 1.21s\tremaining: 2m\n",
      "11:\tlearn: 0.2676645\ttotal: 1.32s\tremaining: 1m 59s\n",
      "12:\tlearn: 0.2611368\ttotal: 1.42s\tremaining: 1m 58s\n",
      "13:\tlearn: 0.2547445\ttotal: 1.54s\tremaining: 1m 59s\n",
      "14:\tlearn: 0.2489933\ttotal: 1.65s\tremaining: 1m 59s\n",
      "15:\tlearn: 0.2445030\ttotal: 1.77s\tremaining: 2m\n",
      "16:\tlearn: 0.2411108\ttotal: 1.87s\tremaining: 1m 59s\n",
      "17:\tlearn: 0.2376310\ttotal: 1.96s\tremaining: 1m 57s\n",
      "18:\tlearn: 0.2344721\ttotal: 2.07s\tremaining: 1m 57s\n",
      "19:\tlearn: 0.2312851\ttotal: 2.16s\tremaining: 1m 56s\n",
      "20:\tlearn: 0.2286525\ttotal: 2.26s\tremaining: 1m 56s\n",
      "21:\tlearn: 0.2265909\ttotal: 2.34s\tremaining: 1m 54s\n",
      "22:\tlearn: 0.2247707\ttotal: 2.43s\tremaining: 1m 53s\n",
      "23:\tlearn: 0.2232624\ttotal: 2.55s\tremaining: 1m 54s\n",
      "24:\tlearn: 0.2217090\ttotal: 2.67s\tremaining: 1m 54s\n",
      "25:\tlearn: 0.2204504\ttotal: 2.79s\tremaining: 1m 55s\n",
      "26:\tlearn: 0.2194207\ttotal: 2.92s\tremaining: 1m 55s\n",
      "27:\tlearn: 0.2183845\ttotal: 3.03s\tremaining: 1m 56s\n",
      "28:\tlearn: 0.2169605\ttotal: 3.14s\tremaining: 1m 55s\n",
      "29:\tlearn: 0.2163964\ttotal: 3.24s\tremaining: 1m 55s\n",
      "30:\tlearn: 0.2152663\ttotal: 3.32s\tremaining: 1m 54s\n",
      "31:\tlearn: 0.2142401\ttotal: 3.42s\tremaining: 1m 54s\n",
      "32:\tlearn: 0.2136969\ttotal: 3.52s\tremaining: 1m 53s\n",
      "33:\tlearn: 0.2131703\ttotal: 3.6s\tremaining: 1m 52s\n",
      "34:\tlearn: 0.2121655\ttotal: 3.69s\tremaining: 1m 52s\n",
      "35:\tlearn: 0.2113201\ttotal: 3.79s\tremaining: 1m 52s\n",
      "36:\tlearn: 0.2104852\ttotal: 3.9s\tremaining: 1m 51s\n",
      "37:\tlearn: 0.2098637\ttotal: 4s\tremaining: 1m 51s\n",
      "38:\tlearn: 0.2094159\ttotal: 4.11s\tremaining: 1m 51s\n",
      "39:\tlearn: 0.2090128\ttotal: 4.2s\tremaining: 1m 51s\n",
      "40:\tlearn: 0.2083896\ttotal: 4.29s\tremaining: 1m 50s\n",
      "41:\tlearn: 0.2076838\ttotal: 4.38s\tremaining: 1m 50s\n",
      "42:\tlearn: 0.2073065\ttotal: 4.46s\tremaining: 1m 49s\n",
      "43:\tlearn: 0.2068715\ttotal: 4.56s\tremaining: 1m 49s\n",
      "44:\tlearn: 0.2065473\ttotal: 4.66s\tremaining: 1m 49s\n",
      "45:\tlearn: 0.2059253\ttotal: 4.77s\tremaining: 1m 49s\n",
      "46:\tlearn: 0.2057033\ttotal: 4.85s\tremaining: 1m 48s\n",
      "47:\tlearn: 0.2054100\ttotal: 4.96s\tremaining: 1m 48s\n",
      "48:\tlearn: 0.2049977\ttotal: 5.08s\tremaining: 1m 49s\n",
      "49:\tlearn: 0.2045471\ttotal: 5.35s\tremaining: 1m 52s\n",
      "50:\tlearn: 0.2041762\ttotal: 5.43s\tremaining: 1m 51s\n",
      "51:\tlearn: 0.2036769\ttotal: 5.52s\tremaining: 1m 51s\n",
      "52:\tlearn: 0.2032916\ttotal: 5.6s\tremaining: 1m 50s\n",
      "53:\tlearn: 0.2029997\ttotal: 5.67s\tremaining: 1m 49s\n",
      "54:\tlearn: 0.2023557\ttotal: 5.75s\tremaining: 1m 49s\n",
      "55:\tlearn: 0.2020005\ttotal: 5.84s\tremaining: 1m 48s\n",
      "56:\tlearn: 0.2015456\ttotal: 5.93s\tremaining: 1m 48s\n",
      "57:\tlearn: 0.2012349\ttotal: 6s\tremaining: 1m 47s\n",
      "58:\tlearn: 0.2008658\ttotal: 6.1s\tremaining: 1m 47s\n",
      "59:\tlearn: 0.2005361\ttotal: 6.18s\tremaining: 1m 47s\n",
      "60:\tlearn: 0.2002211\ttotal: 6.29s\tremaining: 1m 47s\n",
      "61:\tlearn: 0.1997345\ttotal: 6.37s\tremaining: 1m 46s\n",
      "62:\tlearn: 0.1995293\ttotal: 6.46s\tremaining: 1m 46s\n",
      "63:\tlearn: 0.1991899\ttotal: 6.54s\tremaining: 1m 45s\n",
      "64:\tlearn: 0.1988907\ttotal: 6.62s\tremaining: 1m 45s\n",
      "65:\tlearn: 0.1986724\ttotal: 6.7s\tremaining: 1m 45s\n",
      "66:\tlearn: 0.1983916\ttotal: 6.81s\tremaining: 1m 45s\n",
      "67:\tlearn: 0.1980923\ttotal: 6.92s\tremaining: 1m 44s\n",
      "68:\tlearn: 0.1978600\ttotal: 7s\tremaining: 1m 44s\n",
      "69:\tlearn: 0.1975810\ttotal: 7.11s\tremaining: 1m 44s\n",
      "70:\tlearn: 0.1972812\ttotal: 7.21s\tremaining: 1m 44s\n",
      "71:\tlearn: 0.1970294\ttotal: 7.29s\tremaining: 1m 44s\n",
      "72:\tlearn: 0.1965405\ttotal: 7.38s\tremaining: 1m 43s\n",
      "73:\tlearn: 0.1963272\ttotal: 7.48s\tremaining: 1m 43s\n",
      "74:\tlearn: 0.1961052\ttotal: 7.58s\tremaining: 1m 43s\n",
      "75:\tlearn: 0.1957674\ttotal: 7.68s\tremaining: 1m 43s\n",
      "76:\tlearn: 0.1955627\ttotal: 7.77s\tremaining: 1m 43s\n",
      "77:\tlearn: 0.1951911\ttotal: 7.85s\tremaining: 1m 42s\n",
      "78:\tlearn: 0.1949699\ttotal: 7.93s\tremaining: 1m 42s\n",
      "79:\tlearn: 0.1947912\ttotal: 8.01s\tremaining: 1m 42s\n",
      "80:\tlearn: 0.1945654\ttotal: 8.1s\tremaining: 1m 41s\n",
      "81:\tlearn: 0.1942799\ttotal: 8.19s\tremaining: 1m 41s\n",
      "82:\tlearn: 0.1940670\ttotal: 8.28s\tremaining: 1m 41s\n",
      "83:\tlearn: 0.1939093\ttotal: 8.38s\tremaining: 1m 41s\n",
      "84:\tlearn: 0.1937012\ttotal: 8.48s\tremaining: 1m 41s\n",
      "85:\tlearn: 0.1934489\ttotal: 8.57s\tremaining: 1m 41s\n",
      "86:\tlearn: 0.1933405\ttotal: 8.68s\tremaining: 1m 41s\n",
      "87:\tlearn: 0.1931624\ttotal: 8.79s\tremaining: 1m 41s\n",
      "88:\tlearn: 0.1930030\ttotal: 8.97s\tremaining: 1m 41s\n",
      "89:\tlearn: 0.1927991\ttotal: 9.16s\tremaining: 1m 42s\n",
      "90:\tlearn: 0.1924499\ttotal: 9.34s\tremaining: 1m 43s\n",
      "91:\tlearn: 0.1922271\ttotal: 9.51s\tremaining: 1m 44s\n",
      "92:\tlearn: 0.1919415\ttotal: 9.63s\tremaining: 1m 44s\n",
      "93:\tlearn: 0.1917370\ttotal: 9.73s\tremaining: 1m 44s\n",
      "94:\tlearn: 0.1915293\ttotal: 9.84s\tremaining: 1m 44s\n",
      "95:\tlearn: 0.1912957\ttotal: 9.94s\tremaining: 1m 43s\n",
      "96:\tlearn: 0.1910535\ttotal: 10s\tremaining: 1m 43s\n",
      "97:\tlearn: 0.1908324\ttotal: 10.1s\tremaining: 1m 43s\n",
      "98:\tlearn: 0.1905680\ttotal: 10.2s\tremaining: 1m 43s\n",
      "99:\tlearn: 0.1903913\ttotal: 10.3s\tremaining: 1m 43s\n",
      "100:\tlearn: 0.1901790\ttotal: 10.5s\tremaining: 1m 43s\n",
      "101:\tlearn: 0.1898502\ttotal: 10.6s\tremaining: 1m 43s\n",
      "102:\tlearn: 0.1896847\ttotal: 10.7s\tremaining: 1m 43s\n",
      "103:\tlearn: 0.1894854\ttotal: 10.8s\tremaining: 1m 43s\n",
      "104:\tlearn: 0.1891620\ttotal: 10.9s\tremaining: 1m 43s\n",
      "105:\tlearn: 0.1888730\ttotal: 10.9s\tremaining: 1m 42s\n",
      "106:\tlearn: 0.1886814\ttotal: 11s\tremaining: 1m 42s\n",
      "107:\tlearn: 0.1884155\ttotal: 11.1s\tremaining: 1m 41s\n",
      "108:\tlearn: 0.1880341\ttotal: 11.2s\tremaining: 1m 41s\n",
      "109:\tlearn: 0.1878922\ttotal: 11.3s\tremaining: 1m 41s\n",
      "110:\tlearn: 0.1876640\ttotal: 11.3s\tremaining: 1m 41s\n",
      "111:\tlearn: 0.1873413\ttotal: 11.4s\tremaining: 1m 40s\n",
      "112:\tlearn: 0.1870872\ttotal: 11.7s\tremaining: 1m 42s\n",
      "113:\tlearn: 0.1868321\ttotal: 11.9s\tremaining: 1m 43s\n",
      "114:\tlearn: 0.1864908\ttotal: 12.1s\tremaining: 1m 43s\n",
      "115:\tlearn: 0.1861774\ttotal: 12.2s\tremaining: 1m 43s\n",
      "116:\tlearn: 0.1858147\ttotal: 12.4s\tremaining: 1m 44s\n",
      "117:\tlearn: 0.1854831\ttotal: 12.5s\tremaining: 1m 44s\n",
      "118:\tlearn: 0.1850601\ttotal: 12.6s\tremaining: 1m 44s\n",
      "119:\tlearn: 0.1848336\ttotal: 12.8s\tremaining: 1m 44s\n",
      "120:\tlearn: 0.1844551\ttotal: 12.9s\tremaining: 1m 44s\n",
      "121:\tlearn: 0.1840993\ttotal: 13s\tremaining: 1m 43s\n",
      "122:\tlearn: 0.1837356\ttotal: 13.1s\tremaining: 1m 43s\n",
      "123:\tlearn: 0.1833305\ttotal: 13.2s\tremaining: 1m 43s\n",
      "124:\tlearn: 0.1829794\ttotal: 13.3s\tremaining: 1m 43s\n",
      "125:\tlearn: 0.1826756\ttotal: 13.4s\tremaining: 1m 43s\n",
      "126:\tlearn: 0.1824739\ttotal: 13.5s\tremaining: 1m 43s\n",
      "127:\tlearn: 0.1820626\ttotal: 13.6s\tremaining: 1m 43s\n",
      "128:\tlearn: 0.1817135\ttotal: 13.7s\tremaining: 1m 43s\n",
      "129:\tlearn: 0.1814317\ttotal: 13.8s\tremaining: 1m 43s\n",
      "130:\tlearn: 0.1811268\ttotal: 13.9s\tremaining: 1m 43s\n",
      "131:\tlearn: 0.1807744\ttotal: 14s\tremaining: 1m 42s\n",
      "132:\tlearn: 0.1804855\ttotal: 14.1s\tremaining: 1m 42s\n",
      "133:\tlearn: 0.1801491\ttotal: 14.2s\tremaining: 1m 42s\n",
      "134:\tlearn: 0.1797852\ttotal: 14.3s\tremaining: 1m 42s\n",
      "135:\tlearn: 0.1795537\ttotal: 14.3s\tremaining: 1m 41s\n",
      "136:\tlearn: 0.1791949\ttotal: 14.5s\tremaining: 1m 41s\n",
      "137:\tlearn: 0.1787647\ttotal: 14.6s\tremaining: 1m 41s\n",
      "138:\tlearn: 0.1783886\ttotal: 14.6s\tremaining: 1m 41s\n",
      "139:\tlearn: 0.1781108\ttotal: 14.8s\tremaining: 1m 41s\n",
      "140:\tlearn: 0.1778608\ttotal: 14.9s\tremaining: 1m 41s\n",
      "141:\tlearn: 0.1775637\ttotal: 14.9s\tremaining: 1m 40s\n",
      "142:\tlearn: 0.1771217\ttotal: 15.1s\tremaining: 1m 40s\n",
      "143:\tlearn: 0.1768206\ttotal: 15.2s\tremaining: 1m 40s\n",
      "144:\tlearn: 0.1765225\ttotal: 15.2s\tremaining: 1m 40s\n",
      "145:\tlearn: 0.1761696\ttotal: 15.3s\tremaining: 1m 39s\n",
      "146:\tlearn: 0.1758477\ttotal: 15.4s\tremaining: 1m 39s\n",
      "147:\tlearn: 0.1755638\ttotal: 15.5s\tremaining: 1m 39s\n",
      "148:\tlearn: 0.1752903\ttotal: 15.5s\tremaining: 1m 39s\n",
      "149:\tlearn: 0.1750080\ttotal: 15.7s\tremaining: 1m 39s\n",
      "150:\tlearn: 0.1747360\ttotal: 15.8s\tremaining: 1m 39s\n",
      "151:\tlearn: 0.1744717\ttotal: 15.9s\tremaining: 1m 38s\n",
      "152:\tlearn: 0.1741398\ttotal: 16s\tremaining: 1m 38s\n",
      "153:\tlearn: 0.1738465\ttotal: 16.1s\tremaining: 1m 38s\n",
      "154:\tlearn: 0.1735546\ttotal: 16.1s\tremaining: 1m 38s\n",
      "155:\tlearn: 0.1732000\ttotal: 16.2s\tremaining: 1m 38s\n",
      "156:\tlearn: 0.1728589\ttotal: 16.3s\tremaining: 1m 38s\n",
      "157:\tlearn: 0.1724720\ttotal: 16.4s\tremaining: 1m 37s\n",
      "158:\tlearn: 0.1722239\ttotal: 16.5s\tremaining: 1m 37s\n",
      "159:\tlearn: 0.1717985\ttotal: 16.6s\tremaining: 1m 37s\n",
      "160:\tlearn: 0.1714976\ttotal: 16.7s\tremaining: 1m 37s\n",
      "161:\tlearn: 0.1712358\ttotal: 16.8s\tremaining: 1m 37s\n",
      "162:\tlearn: 0.1709304\ttotal: 16.9s\tremaining: 1m 37s\n",
      "163:\tlearn: 0.1705639\ttotal: 17s\tremaining: 1m 37s\n",
      "164:\tlearn: 0.1702323\ttotal: 17.1s\tremaining: 1m 36s\n",
      "165:\tlearn: 0.1698777\ttotal: 17.2s\tremaining: 1m 36s\n",
      "166:\tlearn: 0.1694961\ttotal: 17.3s\tremaining: 1m 36s\n",
      "167:\tlearn: 0.1692099\ttotal: 17.4s\tremaining: 1m 36s\n",
      "168:\tlearn: 0.1688440\ttotal: 17.4s\tremaining: 1m 36s\n",
      "169:\tlearn: 0.1684881\ttotal: 17.5s\tremaining: 1m 35s\n",
      "170:\tlearn: 0.1681448\ttotal: 17.6s\tremaining: 1m 35s\n",
      "171:\tlearn: 0.1679214\ttotal: 17.7s\tremaining: 1m 35s\n",
      "172:\tlearn: 0.1674945\ttotal: 17.8s\tremaining: 1m 35s\n",
      "173:\tlearn: 0.1672504\ttotal: 17.9s\tremaining: 1m 35s\n",
      "174:\tlearn: 0.1669016\ttotal: 18s\tremaining: 1m 35s\n",
      "175:\tlearn: 0.1666925\ttotal: 18.2s\tremaining: 1m 35s\n",
      "176:\tlearn: 0.1663355\ttotal: 18.3s\tremaining: 1m 35s\n",
      "177:\tlearn: 0.1659806\ttotal: 18.4s\tremaining: 1m 35s\n",
      "178:\tlearn: 0.1655979\ttotal: 18.5s\tremaining: 1m 35s\n",
      "179:\tlearn: 0.1652817\ttotal: 18.6s\tremaining: 1m 35s\n",
      "180:\tlearn: 0.1650493\ttotal: 18.7s\tremaining: 1m 34s\n",
      "181:\tlearn: 0.1647614\ttotal: 18.9s\tremaining: 1m 35s\n",
      "182:\tlearn: 0.1644238\ttotal: 19s\tremaining: 1m 35s\n",
      "183:\tlearn: 0.1642012\ttotal: 19.2s\tremaining: 1m 35s\n",
      "184:\tlearn: 0.1639824\ttotal: 19.3s\tremaining: 1m 35s\n",
      "185:\tlearn: 0.1637086\ttotal: 19.4s\tremaining: 1m 35s\n",
      "186:\tlearn: 0.1633988\ttotal: 19.5s\tremaining: 1m 35s\n",
      "187:\tlearn: 0.1631265\ttotal: 19.6s\tremaining: 1m 34s\n",
      "188:\tlearn: 0.1628580\ttotal: 19.7s\tremaining: 1m 34s\n",
      "189:\tlearn: 0.1625941\ttotal: 19.7s\tremaining: 1m 34s\n",
      "190:\tlearn: 0.1623246\ttotal: 19.8s\tremaining: 1m 34s\n",
      "191:\tlearn: 0.1619600\ttotal: 19.9s\tremaining: 1m 34s\n",
      "192:\tlearn: 0.1615941\ttotal: 20s\tremaining: 1m 33s\n",
      "193:\tlearn: 0.1613275\ttotal: 20.1s\tremaining: 1m 33s\n",
      "194:\tlearn: 0.1611005\ttotal: 20.2s\tremaining: 1m 33s\n",
      "195:\tlearn: 0.1608773\ttotal: 20.3s\tremaining: 1m 33s\n",
      "196:\tlearn: 0.1605197\ttotal: 20.4s\tremaining: 1m 33s\n",
      "197:\tlearn: 0.1602089\ttotal: 20.5s\tremaining: 1m 33s\n",
      "198:\tlearn: 0.1599812\ttotal: 20.6s\tremaining: 1m 33s\n",
      "199:\tlearn: 0.1597903\ttotal: 20.7s\tremaining: 1m 33s\n",
      "200:\tlearn: 0.1594430\ttotal: 20.8s\tremaining: 1m 33s\n",
      "201:\tlearn: 0.1591401\ttotal: 20.9s\tremaining: 1m 32s\n",
      "202:\tlearn: 0.1590019\ttotal: 21s\tremaining: 1m 32s\n",
      "203:\tlearn: 0.1587961\ttotal: 21.1s\tremaining: 1m 32s\n",
      "204:\tlearn: 0.1586392\ttotal: 21.2s\tremaining: 1m 32s\n",
      "205:\tlearn: 0.1583933\ttotal: 21.3s\tremaining: 1m 32s\n",
      "206:\tlearn: 0.1582545\ttotal: 21.4s\tremaining: 1m 32s\n",
      "207:\tlearn: 0.1580073\ttotal: 21.5s\tremaining: 1m 32s\n",
      "208:\tlearn: 0.1577338\ttotal: 21.5s\tremaining: 1m 31s\n",
      "209:\tlearn: 0.1574444\ttotal: 21.6s\tremaining: 1m 31s\n",
      "210:\tlearn: 0.1572557\ttotal: 21.8s\tremaining: 1m 31s\n",
      "211:\tlearn: 0.1570216\ttotal: 21.8s\tremaining: 1m 31s\n",
      "212:\tlearn: 0.1567000\ttotal: 21.9s\tremaining: 1m 31s\n",
      "213:\tlearn: 0.1564546\ttotal: 22s\tremaining: 1m 30s\n",
      "214:\tlearn: 0.1562388\ttotal: 22s\tremaining: 1m 30s\n",
      "215:\tlearn: 0.1559384\ttotal: 22.1s\tremaining: 1m 30s\n",
      "216:\tlearn: 0.1557060\ttotal: 22.2s\tremaining: 1m 30s\n",
      "217:\tlearn: 0.1555018\ttotal: 22.3s\tremaining: 1m 30s\n",
      "218:\tlearn: 0.1553160\ttotal: 22.4s\tremaining: 1m 30s\n",
      "219:\tlearn: 0.1550594\ttotal: 22.5s\tremaining: 1m 30s\n",
      "220:\tlearn: 0.1548221\ttotal: 22.6s\tremaining: 1m 29s\n",
      "221:\tlearn: 0.1545821\ttotal: 22.6s\tremaining: 1m 29s\n",
      "222:\tlearn: 0.1543369\ttotal: 22.7s\tremaining: 1m 29s\n",
      "223:\tlearn: 0.1541879\ttotal: 22.8s\tremaining: 1m 29s\n",
      "224:\tlearn: 0.1538965\ttotal: 22.9s\tremaining: 1m 28s\n",
      "225:\tlearn: 0.1536870\ttotal: 23s\tremaining: 1m 28s\n",
      "226:\tlearn: 0.1535044\ttotal: 23s\tremaining: 1m 28s\n",
      "227:\tlearn: 0.1532197\ttotal: 23.1s\tremaining: 1m 28s\n",
      "228:\tlearn: 0.1529470\ttotal: 23.2s\tremaining: 1m 28s\n",
      "229:\tlearn: 0.1527788\ttotal: 23.3s\tremaining: 1m 28s\n",
      "230:\tlearn: 0.1525784\ttotal: 23.4s\tremaining: 1m 27s\n",
      "231:\tlearn: 0.1523000\ttotal: 23.4s\tremaining: 1m 27s\n",
      "232:\tlearn: 0.1519826\ttotal: 23.5s\tremaining: 1m 27s\n",
      "233:\tlearn: 0.1516828\ttotal: 23.6s\tremaining: 1m 27s\n",
      "234:\tlearn: 0.1515499\ttotal: 23.7s\tremaining: 1m 27s\n",
      "235:\tlearn: 0.1512292\ttotal: 23.8s\tremaining: 1m 27s\n",
      "236:\tlearn: 0.1510296\ttotal: 23.9s\tremaining: 1m 26s\n",
      "237:\tlearn: 0.1508452\ttotal: 24s\tremaining: 1m 26s\n",
      "238:\tlearn: 0.1506021\ttotal: 24.1s\tremaining: 1m 26s\n",
      "239:\tlearn: 0.1503906\ttotal: 24.2s\tremaining: 1m 26s\n",
      "240:\tlearn: 0.1502102\ttotal: 24.3s\tremaining: 1m 26s\n",
      "241:\tlearn: 0.1499707\ttotal: 24.4s\tremaining: 1m 26s\n",
      "242:\tlearn: 0.1496740\ttotal: 24.4s\tremaining: 1m 26s\n",
      "243:\tlearn: 0.1494294\ttotal: 24.5s\tremaining: 1m 26s\n",
      "244:\tlearn: 0.1491902\ttotal: 24.6s\tremaining: 1m 25s\n",
      "245:\tlearn: 0.1489164\ttotal: 24.7s\tremaining: 1m 25s\n",
      "246:\tlearn: 0.1486573\ttotal: 24.8s\tremaining: 1m 25s\n",
      "247:\tlearn: 0.1485040\ttotal: 24.9s\tremaining: 1m 25s\n",
      "248:\tlearn: 0.1482558\ttotal: 25s\tremaining: 1m 25s\n",
      "249:\tlearn: 0.1480507\ttotal: 25.1s\tremaining: 1m 25s\n",
      "250:\tlearn: 0.1478240\ttotal: 25.2s\tremaining: 1m 25s\n",
      "251:\tlearn: 0.1475726\ttotal: 25.3s\tremaining: 1m 25s\n",
      "252:\tlearn: 0.1473688\ttotal: 25.3s\tremaining: 1m 24s\n",
      "253:\tlearn: 0.1471975\ttotal: 25.4s\tremaining: 1m 24s\n",
      "254:\tlearn: 0.1468564\ttotal: 25.5s\tremaining: 1m 24s\n",
      "255:\tlearn: 0.1465762\ttotal: 25.6s\tremaining: 1m 24s\n",
      "256:\tlearn: 0.1464676\ttotal: 25.7s\tremaining: 1m 24s\n",
      "257:\tlearn: 0.1461773\ttotal: 25.8s\tremaining: 1m 24s\n",
      "258:\tlearn: 0.1460536\ttotal: 25.9s\tremaining: 1m 24s\n",
      "259:\tlearn: 0.1457274\ttotal: 26s\tremaining: 1m 24s\n",
      "260:\tlearn: 0.1455179\ttotal: 26.1s\tremaining: 1m 23s\n",
      "261:\tlearn: 0.1453146\ttotal: 26.2s\tremaining: 1m 23s\n",
      "262:\tlearn: 0.1451055\ttotal: 26.3s\tremaining: 1m 23s\n",
      "263:\tlearn: 0.1448709\ttotal: 26.3s\tremaining: 1m 23s\n",
      "264:\tlearn: 0.1446686\ttotal: 26.4s\tremaining: 1m 23s\n",
      "265:\tlearn: 0.1445328\ttotal: 26.5s\tremaining: 1m 23s\n",
      "266:\tlearn: 0.1442924\ttotal: 26.6s\tremaining: 1m 22s\n",
      "267:\tlearn: 0.1440789\ttotal: 26.7s\tremaining: 1m 22s\n",
      "268:\tlearn: 0.1437877\ttotal: 26.8s\tremaining: 1m 22s\n",
      "269:\tlearn: 0.1435498\ttotal: 26.9s\tremaining: 1m 22s\n",
      "270:\tlearn: 0.1433073\ttotal: 27s\tremaining: 1m 22s\n",
      "271:\tlearn: 0.1430293\ttotal: 27s\tremaining: 1m 22s\n",
      "272:\tlearn: 0.1427870\ttotal: 27.2s\tremaining: 1m 22s\n",
      "273:\tlearn: 0.1426431\ttotal: 27.3s\tremaining: 1m 22s\n",
      "274:\tlearn: 0.1423537\ttotal: 27.4s\tremaining: 1m 22s\n",
      "275:\tlearn: 0.1422573\ttotal: 27.5s\tremaining: 1m 22s\n",
      "276:\tlearn: 0.1421055\ttotal: 27.6s\tremaining: 1m 21s\n",
      "277:\tlearn: 0.1419309\ttotal: 27.7s\tremaining: 1m 21s\n",
      "278:\tlearn: 0.1416810\ttotal: 27.8s\tremaining: 1m 21s\n",
      "279:\tlearn: 0.1414074\ttotal: 28s\tremaining: 1m 22s\n",
      "280:\tlearn: 0.1411807\ttotal: 28.2s\tremaining: 1m 22s\n",
      "281:\tlearn: 0.1409498\ttotal: 28.3s\tremaining: 1m 22s\n",
      "282:\tlearn: 0.1407518\ttotal: 28.4s\tremaining: 1m 21s\n",
      "283:\tlearn: 0.1405824\ttotal: 28.4s\tremaining: 1m 21s\n",
      "284:\tlearn: 0.1404061\ttotal: 28.5s\tremaining: 1m 21s\n",
      "285:\tlearn: 0.1402630\ttotal: 28.6s\tremaining: 1m 21s\n",
      "286:\tlearn: 0.1400527\ttotal: 28.6s\tremaining: 1m 21s\n",
      "287:\tlearn: 0.1398600\ttotal: 28.8s\tremaining: 1m 21s\n",
      "288:\tlearn: 0.1396827\ttotal: 28.9s\tremaining: 1m 21s\n",
      "289:\tlearn: 0.1394399\ttotal: 29s\tremaining: 1m 20s\n",
      "290:\tlearn: 0.1392258\ttotal: 29.1s\tremaining: 1m 20s\n",
      "291:\tlearn: 0.1389262\ttotal: 29.1s\tremaining: 1m 20s\n",
      "292:\tlearn: 0.1387155\ttotal: 29.2s\tremaining: 1m 20s\n",
      "293:\tlearn: 0.1384855\ttotal: 29.3s\tremaining: 1m 20s\n",
      "294:\tlearn: 0.1382840\ttotal: 29.4s\tremaining: 1m 20s\n",
      "295:\tlearn: 0.1381320\ttotal: 29.5s\tremaining: 1m 20s\n",
      "296:\tlearn: 0.1378918\ttotal: 29.6s\tremaining: 1m 19s\n",
      "297:\tlearn: 0.1377051\ttotal: 29.7s\tremaining: 1m 19s\n",
      "298:\tlearn: 0.1374403\ttotal: 29.8s\tremaining: 1m 19s\n",
      "299:\tlearn: 0.1372570\ttotal: 29.9s\tremaining: 1m 19s\n",
      "300:\tlearn: 0.1370484\ttotal: 30s\tremaining: 1m 19s\n",
      "301:\tlearn: 0.1368262\ttotal: 30s\tremaining: 1m 19s\n",
      "302:\tlearn: 0.1365084\ttotal: 30.1s\tremaining: 1m 19s\n",
      "303:\tlearn: 0.1362378\ttotal: 30.2s\tremaining: 1m 19s\n",
      "304:\tlearn: 0.1361035\ttotal: 30.3s\tremaining: 1m 18s\n",
      "305:\tlearn: 0.1358945\ttotal: 30.4s\tremaining: 1m 18s\n",
      "306:\tlearn: 0.1357432\ttotal: 30.5s\tremaining: 1m 18s\n",
      "307:\tlearn: 0.1356053\ttotal: 30.6s\tremaining: 1m 18s\n",
      "308:\tlearn: 0.1353583\ttotal: 30.7s\tremaining: 1m 18s\n",
      "309:\tlearn: 0.1351990\ttotal: 30.8s\tremaining: 1m 18s\n",
      "310:\tlearn: 0.1350720\ttotal: 30.9s\tremaining: 1m 18s\n",
      "311:\tlearn: 0.1347931\ttotal: 31s\tremaining: 1m 18s\n",
      "312:\tlearn: 0.1345247\ttotal: 31.1s\tremaining: 1m 18s\n",
      "313:\tlearn: 0.1344418\ttotal: 31.2s\tremaining: 1m 18s\n",
      "314:\tlearn: 0.1342923\ttotal: 31.2s\tremaining: 1m 17s\n",
      "315:\tlearn: 0.1341300\ttotal: 31.3s\tremaining: 1m 17s\n",
      "316:\tlearn: 0.1339378\ttotal: 31.4s\tremaining: 1m 17s\n",
      "317:\tlearn: 0.1337428\ttotal: 31.5s\tremaining: 1m 17s\n",
      "318:\tlearn: 0.1335213\ttotal: 31.6s\tremaining: 1m 17s\n",
      "319:\tlearn: 0.1332978\ttotal: 31.7s\tremaining: 1m 17s\n",
      "320:\tlearn: 0.1331618\ttotal: 31.7s\tremaining: 1m 17s\n",
      "321:\tlearn: 0.1330456\ttotal: 31.8s\tremaining: 1m 16s\n",
      "322:\tlearn: 0.1328692\ttotal: 31.9s\tremaining: 1m 16s\n",
      "323:\tlearn: 0.1326984\ttotal: 32s\tremaining: 1m 16s\n",
      "324:\tlearn: 0.1325729\ttotal: 32.1s\tremaining: 1m 16s\n",
      "325:\tlearn: 0.1323114\ttotal: 32.2s\tremaining: 1m 16s\n",
      "326:\tlearn: 0.1320002\ttotal: 32.3s\tremaining: 1m 16s\n",
      "327:\tlearn: 0.1317365\ttotal: 32.4s\tremaining: 1m 16s\n",
      "328:\tlearn: 0.1314912\ttotal: 32.5s\tremaining: 1m 16s\n",
      "329:\tlearn: 0.1313743\ttotal: 32.5s\tremaining: 1m 15s\n",
      "330:\tlearn: 0.1311833\ttotal: 32.6s\tremaining: 1m 15s\n",
      "331:\tlearn: 0.1309348\ttotal: 32.7s\tremaining: 1m 15s\n",
      "332:\tlearn: 0.1307464\ttotal: 32.8s\tremaining: 1m 15s\n",
      "333:\tlearn: 0.1305205\ttotal: 32.9s\tremaining: 1m 15s\n",
      "334:\tlearn: 0.1303873\ttotal: 33s\tremaining: 1m 15s\n",
      "335:\tlearn: 0.1302064\ttotal: 33s\tremaining: 1m 15s\n",
      "336:\tlearn: 0.1299904\ttotal: 33.1s\tremaining: 1m 15s\n",
      "337:\tlearn: 0.1298283\ttotal: 33.2s\tremaining: 1m 14s\n",
      "338:\tlearn: 0.1296734\ttotal: 33.3s\tremaining: 1m 14s\n",
      "339:\tlearn: 0.1295235\ttotal: 33.4s\tremaining: 1m 14s\n",
      "340:\tlearn: 0.1293829\ttotal: 33.5s\tremaining: 1m 14s\n",
      "341:\tlearn: 0.1291820\ttotal: 33.6s\tremaining: 1m 14s\n",
      "342:\tlearn: 0.1289831\ttotal: 33.7s\tremaining: 1m 14s\n",
      "343:\tlearn: 0.1287925\ttotal: 33.7s\tremaining: 1m 14s\n",
      "344:\tlearn: 0.1286332\ttotal: 33.8s\tremaining: 1m 14s\n",
      "345:\tlearn: 0.1284506\ttotal: 33.9s\tremaining: 1m 13s\n",
      "346:\tlearn: 0.1282463\ttotal: 34s\tremaining: 1m 13s\n",
      "347:\tlearn: 0.1280868\ttotal: 34.1s\tremaining: 1m 13s\n",
      "348:\tlearn: 0.1279285\ttotal: 34.2s\tremaining: 1m 13s\n",
      "349:\tlearn: 0.1277407\ttotal: 34.3s\tremaining: 1m 13s\n",
      "350:\tlearn: 0.1276010\ttotal: 34.4s\tremaining: 1m 13s\n",
      "351:\tlearn: 0.1274149\ttotal: 34.5s\tremaining: 1m 13s\n",
      "352:\tlearn: 0.1271838\ttotal: 34.6s\tremaining: 1m 13s\n",
      "353:\tlearn: 0.1270873\ttotal: 34.7s\tremaining: 1m 13s\n",
      "354:\tlearn: 0.1269216\ttotal: 34.7s\tremaining: 1m 12s\n",
      "355:\tlearn: 0.1267805\ttotal: 34.8s\tremaining: 1m 12s\n",
      "356:\tlearn: 0.1266631\ttotal: 34.9s\tremaining: 1m 12s\n",
      "357:\tlearn: 0.1265324\ttotal: 35s\tremaining: 1m 12s\n",
      "358:\tlearn: 0.1263538\ttotal: 35.1s\tremaining: 1m 12s\n",
      "359:\tlearn: 0.1262276\ttotal: 35.1s\tremaining: 1m 12s\n",
      "360:\tlearn: 0.1260764\ttotal: 35.2s\tremaining: 1m 12s\n",
      "361:\tlearn: 0.1259462\ttotal: 35.3s\tremaining: 1m 11s\n",
      "362:\tlearn: 0.1256531\ttotal: 35.4s\tremaining: 1m 11s\n",
      "363:\tlearn: 0.1254775\ttotal: 35.5s\tremaining: 1m 11s\n",
      "364:\tlearn: 0.1252131\ttotal: 35.6s\tremaining: 1m 11s\n",
      "365:\tlearn: 0.1250487\ttotal: 35.7s\tremaining: 1m 11s\n",
      "366:\tlearn: 0.1249274\ttotal: 35.7s\tremaining: 1m 11s\n",
      "367:\tlearn: 0.1247501\ttotal: 35.8s\tremaining: 1m 11s\n",
      "368:\tlearn: 0.1245910\ttotal: 35.9s\tremaining: 1m 11s\n",
      "369:\tlearn: 0.1244142\ttotal: 36s\tremaining: 1m 10s\n",
      "370:\tlearn: 0.1243209\ttotal: 36.1s\tremaining: 1m 10s\n",
      "371:\tlearn: 0.1242428\ttotal: 36.1s\tremaining: 1m 10s\n",
      "372:\tlearn: 0.1241118\ttotal: 36.2s\tremaining: 1m 10s\n",
      "373:\tlearn: 0.1239818\ttotal: 36.3s\tremaining: 1m 10s\n",
      "374:\tlearn: 0.1238473\ttotal: 36.4s\tremaining: 1m 10s\n",
      "375:\tlearn: 0.1236953\ttotal: 36.5s\tremaining: 1m 10s\n",
      "376:\tlearn: 0.1236218\ttotal: 36.6s\tremaining: 1m 10s\n",
      "377:\tlearn: 0.1234086\ttotal: 36.7s\tremaining: 1m 10s\n",
      "378:\tlearn: 0.1231512\ttotal: 36.8s\tremaining: 1m 9s\n",
      "379:\tlearn: 0.1230166\ttotal: 36.8s\tremaining: 1m 9s\n",
      "380:\tlearn: 0.1228422\ttotal: 36.9s\tremaining: 1m 9s\n",
      "381:\tlearn: 0.1226836\ttotal: 37s\tremaining: 1m 9s\n",
      "382:\tlearn: 0.1224684\ttotal: 37.1s\tremaining: 1m 9s\n",
      "383:\tlearn: 0.1223429\ttotal: 37.2s\tremaining: 1m 9s\n",
      "384:\tlearn: 0.1221892\ttotal: 37.3s\tremaining: 1m 9s\n",
      "385:\tlearn: 0.1219792\ttotal: 37.3s\tremaining: 1m 9s\n",
      "386:\tlearn: 0.1218240\ttotal: 37.4s\tremaining: 1m 8s\n",
      "387:\tlearn: 0.1216399\ttotal: 37.5s\tremaining: 1m 8s\n",
      "388:\tlearn: 0.1214440\ttotal: 37.6s\tremaining: 1m 8s\n",
      "389:\tlearn: 0.1213159\ttotal: 37.7s\tremaining: 1m 8s\n",
      "390:\tlearn: 0.1211349\ttotal: 37.8s\tremaining: 1m 8s\n",
      "391:\tlearn: 0.1209685\ttotal: 37.8s\tremaining: 1m 8s\n",
      "392:\tlearn: 0.1208198\ttotal: 37.9s\tremaining: 1m 8s\n",
      "393:\tlearn: 0.1207016\ttotal: 38s\tremaining: 1m 8s\n",
      "394:\tlearn: 0.1205295\ttotal: 38.1s\tremaining: 1m 7s\n",
      "395:\tlearn: 0.1204223\ttotal: 38.2s\tremaining: 1m 7s\n",
      "396:\tlearn: 0.1203484\ttotal: 38.2s\tremaining: 1m 7s\n",
      "397:\tlearn: 0.1201476\ttotal: 38.3s\tremaining: 1m 7s\n",
      "398:\tlearn: 0.1199939\ttotal: 38.4s\tremaining: 1m 7s\n",
      "399:\tlearn: 0.1198594\ttotal: 38.5s\tremaining: 1m 7s\n",
      "400:\tlearn: 0.1197389\ttotal: 38.6s\tremaining: 1m 7s\n",
      "401:\tlearn: 0.1196139\ttotal: 38.7s\tremaining: 1m 7s\n",
      "402:\tlearn: 0.1194875\ttotal: 38.7s\tremaining: 1m 7s\n",
      "403:\tlearn: 0.1193410\ttotal: 38.8s\tremaining: 1m 6s\n",
      "404:\tlearn: 0.1191084\ttotal: 38.9s\tremaining: 1m 6s\n",
      "405:\tlearn: 0.1188856\ttotal: 39s\tremaining: 1m 6s\n",
      "406:\tlearn: 0.1187321\ttotal: 39.1s\tremaining: 1m 6s\n",
      "407:\tlearn: 0.1185751\ttotal: 39.1s\tremaining: 1m 6s\n",
      "408:\tlearn: 0.1184099\ttotal: 39.2s\tremaining: 1m 6s\n",
      "409:\tlearn: 0.1182208\ttotal: 39.3s\tremaining: 1m 6s\n",
      "410:\tlearn: 0.1181045\ttotal: 39.4s\tremaining: 1m 6s\n",
      "411:\tlearn: 0.1179760\ttotal: 39.5s\tremaining: 1m 5s\n",
      "412:\tlearn: 0.1178631\ttotal: 39.6s\tremaining: 1m 5s\n",
      "413:\tlearn: 0.1176839\ttotal: 39.8s\tremaining: 1m 5s\n",
      "414:\tlearn: 0.1175603\ttotal: 40s\tremaining: 1m 5s\n",
      "415:\tlearn: 0.1174375\ttotal: 40s\tremaining: 1m 5s\n",
      "416:\tlearn: 0.1172995\ttotal: 40.1s\tremaining: 1m 5s\n",
      "417:\tlearn: 0.1171987\ttotal: 40.2s\tremaining: 1m 5s\n",
      "418:\tlearn: 0.1170426\ttotal: 40.3s\tremaining: 1m 5s\n",
      "419:\tlearn: 0.1168580\ttotal: 40.4s\tremaining: 1m 5s\n",
      "420:\tlearn: 0.1167519\ttotal: 40.4s\tremaining: 1m 5s\n",
      "421:\tlearn: 0.1165903\ttotal: 40.5s\tremaining: 1m 5s\n",
      "422:\tlearn: 0.1164644\ttotal: 40.6s\tremaining: 1m 4s\n",
      "423:\tlearn: 0.1163417\ttotal: 40.7s\tremaining: 1m 4s\n",
      "424:\tlearn: 0.1161076\ttotal: 40.8s\tremaining: 1m 4s\n",
      "425:\tlearn: 0.1159037\ttotal: 40.9s\tremaining: 1m 4s\n",
      "426:\tlearn: 0.1157912\ttotal: 40.9s\tremaining: 1m 4s\n",
      "427:\tlearn: 0.1155689\ttotal: 41.1s\tremaining: 1m 4s\n",
      "428:\tlearn: 0.1153798\ttotal: 41.1s\tremaining: 1m 4s\n",
      "429:\tlearn: 0.1152403\ttotal: 41.2s\tremaining: 1m 4s\n",
      "430:\tlearn: 0.1151519\ttotal: 41.3s\tremaining: 1m 4s\n",
      "431:\tlearn: 0.1149623\ttotal: 41.4s\tremaining: 1m 3s\n",
      "432:\tlearn: 0.1148557\ttotal: 41.5s\tremaining: 1m 3s\n",
      "433:\tlearn: 0.1147787\ttotal: 41.6s\tremaining: 1m 3s\n",
      "434:\tlearn: 0.1145852\ttotal: 41.7s\tremaining: 1m 3s\n",
      "435:\tlearn: 0.1144381\ttotal: 41.8s\tremaining: 1m 3s\n",
      "436:\tlearn: 0.1142996\ttotal: 41.9s\tremaining: 1m 3s\n",
      "437:\tlearn: 0.1141843\ttotal: 42s\tremaining: 1m 3s\n",
      "438:\tlearn: 0.1141256\ttotal: 42s\tremaining: 1m 3s\n",
      "439:\tlearn: 0.1138761\ttotal: 42.1s\tremaining: 1m 3s\n",
      "440:\tlearn: 0.1137197\ttotal: 42.2s\tremaining: 1m 3s\n",
      "441:\tlearn: 0.1135101\ttotal: 42.3s\tremaining: 1m 3s\n",
      "442:\tlearn: 0.1133312\ttotal: 42.4s\tremaining: 1m 2s\n",
      "443:\tlearn: 0.1132221\ttotal: 42.5s\tremaining: 1m 2s\n",
      "444:\tlearn: 0.1130333\ttotal: 42.6s\tremaining: 1m 2s\n",
      "445:\tlearn: 0.1129020\ttotal: 42.7s\tremaining: 1m 2s\n",
      "446:\tlearn: 0.1128092\ttotal: 42.7s\tremaining: 1m 2s\n",
      "447:\tlearn: 0.1126846\ttotal: 42.8s\tremaining: 1m 2s\n",
      "448:\tlearn: 0.1125460\ttotal: 42.9s\tremaining: 1m 2s\n",
      "449:\tlearn: 0.1123738\ttotal: 43s\tremaining: 1m 2s\n",
      "450:\tlearn: 0.1122202\ttotal: 43.1s\tremaining: 1m 2s\n",
      "451:\tlearn: 0.1120078\ttotal: 43.2s\tremaining: 1m 1s\n",
      "452:\tlearn: 0.1118611\ttotal: 43.3s\tremaining: 1m 1s\n",
      "453:\tlearn: 0.1116769\ttotal: 43.4s\tremaining: 1m 1s\n",
      "454:\tlearn: 0.1115052\ttotal: 43.5s\tremaining: 1m 1s\n",
      "455:\tlearn: 0.1113325\ttotal: 43.6s\tremaining: 1m 1s\n",
      "456:\tlearn: 0.1111463\ttotal: 43.7s\tremaining: 1m 1s\n",
      "457:\tlearn: 0.1110452\ttotal: 43.8s\tremaining: 1m 1s\n",
      "458:\tlearn: 0.1108963\ttotal: 43.9s\tremaining: 1m 1s\n",
      "459:\tlearn: 0.1106832\ttotal: 44s\tremaining: 1m 1s\n",
      "460:\tlearn: 0.1105258\ttotal: 44.1s\tremaining: 1m 1s\n",
      "461:\tlearn: 0.1104262\ttotal: 44.2s\tremaining: 1m 1s\n",
      "462:\tlearn: 0.1102554\ttotal: 44.3s\tremaining: 1m\n",
      "463:\tlearn: 0.1101039\ttotal: 44.3s\tremaining: 1m\n",
      "464:\tlearn: 0.1099020\ttotal: 44.4s\tremaining: 1m\n",
      "465:\tlearn: 0.1098254\ttotal: 44.5s\tremaining: 1m\n",
      "466:\tlearn: 0.1096885\ttotal: 44.6s\tremaining: 1m\n",
      "467:\tlearn: 0.1095611\ttotal: 44.7s\tremaining: 1m\n",
      "468:\tlearn: 0.1095099\ttotal: 44.7s\tremaining: 1m\n",
      "469:\tlearn: 0.1093439\ttotal: 44.8s\tremaining: 1m\n",
      "470:\tlearn: 0.1092603\ttotal: 44.9s\tremaining: 1m\n",
      "471:\tlearn: 0.1091669\ttotal: 45s\tremaining: 59.9s\n",
      "472:\tlearn: 0.1090420\ttotal: 45.1s\tremaining: 59.8s\n",
      "473:\tlearn: 0.1089128\ttotal: 45.2s\tremaining: 59.7s\n",
      "474:\tlearn: 0.1087971\ttotal: 45.3s\tremaining: 59.6s\n",
      "475:\tlearn: 0.1087102\ttotal: 45.4s\tremaining: 59.5s\n",
      "476:\tlearn: 0.1086124\ttotal: 45.4s\tremaining: 59.3s\n",
      "477:\tlearn: 0.1084951\ttotal: 45.5s\tremaining: 59.2s\n",
      "478:\tlearn: 0.1083743\ttotal: 45.6s\tremaining: 59.2s\n",
      "479:\tlearn: 0.1082292\ttotal: 45.7s\tremaining: 59s\n",
      "480:\tlearn: 0.1081377\ttotal: 45.8s\tremaining: 58.9s\n",
      "481:\tlearn: 0.1080568\ttotal: 45.9s\tremaining: 58.8s\n",
      "482:\tlearn: 0.1078852\ttotal: 46s\tremaining: 58.7s\n",
      "483:\tlearn: 0.1077425\ttotal: 46.1s\tremaining: 58.6s\n",
      "484:\tlearn: 0.1076147\ttotal: 46.1s\tremaining: 58.5s\n",
      "485:\tlearn: 0.1074673\ttotal: 46.2s\tremaining: 58.4s\n",
      "486:\tlearn: 0.1073299\ttotal: 46.3s\tremaining: 58.3s\n",
      "487:\tlearn: 0.1071993\ttotal: 46.4s\tremaining: 58.2s\n",
      "488:\tlearn: 0.1070896\ttotal: 46.5s\tremaining: 58.1s\n",
      "489:\tlearn: 0.1069439\ttotal: 46.6s\tremaining: 58s\n",
      "490:\tlearn: 0.1068380\ttotal: 46.7s\tremaining: 57.9s\n",
      "491:\tlearn: 0.1067414\ttotal: 46.8s\tremaining: 57.8s\n",
      "492:\tlearn: 0.1065501\ttotal: 46.9s\tremaining: 57.7s\n",
      "493:\tlearn: 0.1064762\ttotal: 46.9s\tremaining: 57.6s\n",
      "494:\tlearn: 0.1063917\ttotal: 47s\tremaining: 57.5s\n",
      "495:\tlearn: 0.1062125\ttotal: 47.1s\tremaining: 57.4s\n",
      "496:\tlearn: 0.1061013\ttotal: 47.2s\tremaining: 57.2s\n",
      "497:\tlearn: 0.1060361\ttotal: 47.3s\tremaining: 57.1s\n",
      "498:\tlearn: 0.1059437\ttotal: 47.3s\tremaining: 57s\n",
      "499:\tlearn: 0.1058412\ttotal: 47.4s\tremaining: 56.9s\n",
      "500:\tlearn: 0.1057174\ttotal: 47.5s\tremaining: 56.8s\n",
      "501:\tlearn: 0.1056045\ttotal: 47.6s\tremaining: 56.7s\n",
      "502:\tlearn: 0.1055091\ttotal: 47.7s\tremaining: 56.6s\n",
      "503:\tlearn: 0.1054101\ttotal: 47.7s\tremaining: 56.4s\n",
      "504:\tlearn: 0.1053413\ttotal: 47.8s\tremaining: 56.3s\n",
      "505:\tlearn: 0.1051799\ttotal: 47.9s\tremaining: 56.3s\n",
      "506:\tlearn: 0.1050329\ttotal: 48.1s\tremaining: 56.3s\n",
      "507:\tlearn: 0.1049026\ttotal: 48.3s\tremaining: 56.2s\n",
      "508:\tlearn: 0.1047995\ttotal: 48.3s\tremaining: 56.1s\n",
      "509:\tlearn: 0.1046799\ttotal: 48.4s\tremaining: 56s\n",
      "510:\tlearn: 0.1044903\ttotal: 48.5s\tremaining: 55.9s\n",
      "511:\tlearn: 0.1043147\ttotal: 48.6s\tremaining: 55.8s\n",
      "512:\tlearn: 0.1041720\ttotal: 48.7s\tremaining: 55.7s\n",
      "513:\tlearn: 0.1040725\ttotal: 48.8s\tremaining: 55.6s\n",
      "514:\tlearn: 0.1039606\ttotal: 49.1s\tremaining: 55.7s\n",
      "515:\tlearn: 0.1038042\ttotal: 49.2s\tremaining: 55.6s\n",
      "516:\tlearn: 0.1036809\ttotal: 49.2s\tremaining: 55.5s\n",
      "517:\tlearn: 0.1035501\ttotal: 49.3s\tremaining: 55.4s\n",
      "518:\tlearn: 0.1033602\ttotal: 49.4s\tremaining: 55.3s\n",
      "519:\tlearn: 0.1032432\ttotal: 49.5s\tremaining: 55.2s\n",
      "520:\tlearn: 0.1030450\ttotal: 49.6s\tremaining: 55.1s\n",
      "521:\tlearn: 0.1029356\ttotal: 49.6s\tremaining: 55s\n",
      "522:\tlearn: 0.1027455\ttotal: 49.7s\tremaining: 54.8s\n",
      "523:\tlearn: 0.1025771\ttotal: 49.8s\tremaining: 54.8s\n",
      "524:\tlearn: 0.1024072\ttotal: 49.9s\tremaining: 54.7s\n",
      "525:\tlearn: 0.1023188\ttotal: 50s\tremaining: 54.6s\n",
      "526:\tlearn: 0.1021731\ttotal: 50.1s\tremaining: 54.5s\n",
      "527:\tlearn: 0.1020588\ttotal: 50.2s\tremaining: 54.3s\n",
      "528:\tlearn: 0.1019395\ttotal: 50.2s\tremaining: 54.2s\n",
      "529:\tlearn: 0.1018523\ttotal: 50.3s\tremaining: 54.1s\n",
      "530:\tlearn: 0.1016830\ttotal: 50.4s\tremaining: 54s\n",
      "531:\tlearn: 0.1015417\ttotal: 50.5s\tremaining: 53.9s\n",
      "532:\tlearn: 0.1014534\ttotal: 50.6s\tremaining: 53.8s\n",
      "533:\tlearn: 0.1013199\ttotal: 50.7s\tremaining: 53.7s\n",
      "534:\tlearn: 0.1011142\ttotal: 50.8s\tremaining: 53.6s\n",
      "535:\tlearn: 0.1009808\ttotal: 50.9s\tremaining: 53.5s\n",
      "536:\tlearn: 0.1008278\ttotal: 51s\tremaining: 53.4s\n",
      "537:\tlearn: 0.1006987\ttotal: 51s\tremaining: 53.3s\n",
      "538:\tlearn: 0.1006272\ttotal: 51.1s\tremaining: 53.2s\n",
      "539:\tlearn: 0.1005061\ttotal: 51.2s\tremaining: 53.1s\n",
      "540:\tlearn: 0.1003626\ttotal: 51.3s\tremaining: 53s\n",
      "541:\tlearn: 0.1002293\ttotal: 51.4s\tremaining: 52.9s\n",
      "542:\tlearn: 0.1000501\ttotal: 51.5s\tremaining: 52.8s\n",
      "543:\tlearn: 0.0998258\ttotal: 51.6s\tremaining: 52.7s\n",
      "544:\tlearn: 0.0996493\ttotal: 51.6s\tremaining: 52.6s\n",
      "545:\tlearn: 0.0995840\ttotal: 51.7s\tremaining: 52.5s\n",
      "546:\tlearn: 0.0995388\ttotal: 51.8s\tremaining: 52.4s\n",
      "547:\tlearn: 0.0994669\ttotal: 51.9s\tremaining: 52.3s\n",
      "548:\tlearn: 0.0993141\ttotal: 52s\tremaining: 52.2s\n",
      "549:\tlearn: 0.0991691\ttotal: 52.1s\tremaining: 52.1s\n",
      "550:\tlearn: 0.0990908\ttotal: 52.2s\tremaining: 52s\n",
      "551:\tlearn: 0.0989790\ttotal: 52.3s\tremaining: 51.9s\n",
      "552:\tlearn: 0.0988763\ttotal: 52.4s\tremaining: 51.8s\n",
      "553:\tlearn: 0.0987773\ttotal: 52.4s\tremaining: 51.7s\n",
      "554:\tlearn: 0.0986278\ttotal: 52.5s\tremaining: 51.6s\n",
      "555:\tlearn: 0.0985404\ttotal: 52.6s\tremaining: 51.5s\n",
      "556:\tlearn: 0.0984009\ttotal: 52.7s\tremaining: 51.4s\n",
      "557:\tlearn: 0.0982905\ttotal: 52.8s\tremaining: 51.3s\n",
      "558:\tlearn: 0.0980948\ttotal: 52.9s\tremaining: 51.2s\n",
      "559:\tlearn: 0.0979641\ttotal: 53s\tremaining: 51.1s\n",
      "560:\tlearn: 0.0978377\ttotal: 53s\tremaining: 51s\n",
      "561:\tlearn: 0.0977271\ttotal: 53.2s\tremaining: 50.9s\n",
      "562:\tlearn: 0.0975738\ttotal: 53.3s\tremaining: 50.8s\n",
      "563:\tlearn: 0.0974867\ttotal: 53.3s\tremaining: 50.7s\n",
      "564:\tlearn: 0.0973930\ttotal: 53.4s\tremaining: 50.6s\n",
      "565:\tlearn: 0.0972116\ttotal: 53.5s\tremaining: 50.5s\n",
      "566:\tlearn: 0.0970636\ttotal: 53.6s\tremaining: 50.4s\n",
      "567:\tlearn: 0.0968862\ttotal: 53.7s\tremaining: 50.3s\n",
      "568:\tlearn: 0.0967777\ttotal: 53.7s\tremaining: 50.2s\n",
      "569:\tlearn: 0.0965676\ttotal: 53.8s\tremaining: 50.1s\n",
      "570:\tlearn: 0.0964773\ttotal: 53.9s\tremaining: 50s\n",
      "571:\tlearn: 0.0963496\ttotal: 54s\tremaining: 49.9s\n",
      "572:\tlearn: 0.0962701\ttotal: 54.1s\tremaining: 49.8s\n",
      "573:\tlearn: 0.0961683\ttotal: 54.2s\tremaining: 49.7s\n",
      "574:\tlearn: 0.0960943\ttotal: 54.3s\tremaining: 49.6s\n",
      "575:\tlearn: 0.0960259\ttotal: 54.4s\tremaining: 49.5s\n",
      "576:\tlearn: 0.0959139\ttotal: 54.5s\tremaining: 49.4s\n",
      "577:\tlearn: 0.0958155\ttotal: 54.6s\tremaining: 49.3s\n",
      "578:\tlearn: 0.0957396\ttotal: 54.7s\tremaining: 49.2s\n",
      "579:\tlearn: 0.0956362\ttotal: 54.7s\tremaining: 49.1s\n",
      "580:\tlearn: 0.0955363\ttotal: 54.8s\tremaining: 49s\n",
      "581:\tlearn: 0.0954399\ttotal: 54.9s\tremaining: 48.9s\n",
      "582:\tlearn: 0.0953639\ttotal: 55s\tremaining: 48.8s\n",
      "583:\tlearn: 0.0952410\ttotal: 55.1s\tremaining: 48.6s\n",
      "584:\tlearn: 0.0950915\ttotal: 55.1s\tremaining: 48.5s\n",
      "585:\tlearn: 0.0949634\ttotal: 55.2s\tremaining: 48.4s\n",
      "586:\tlearn: 0.0948038\ttotal: 55.3s\tremaining: 48.3s\n",
      "587:\tlearn: 0.0947323\ttotal: 55.4s\tremaining: 48.2s\n",
      "588:\tlearn: 0.0945645\ttotal: 55.4s\tremaining: 48.1s\n",
      "589:\tlearn: 0.0944322\ttotal: 55.5s\tremaining: 48s\n",
      "590:\tlearn: 0.0943319\ttotal: 55.6s\tremaining: 47.9s\n",
      "591:\tlearn: 0.0942378\ttotal: 55.7s\tremaining: 47.8s\n",
      "592:\tlearn: 0.0940914\ttotal: 55.8s\tremaining: 47.7s\n",
      "593:\tlearn: 0.0940161\ttotal: 55.8s\tremaining: 47.6s\n",
      "594:\tlearn: 0.0939053\ttotal: 55.9s\tremaining: 47.5s\n",
      "595:\tlearn: 0.0938450\ttotal: 56s\tremaining: 47.4s\n",
      "596:\tlearn: 0.0937058\ttotal: 56.1s\tremaining: 47.3s\n",
      "597:\tlearn: 0.0935824\ttotal: 56.2s\tremaining: 47.2s\n",
      "598:\tlearn: 0.0934683\ttotal: 56.3s\tremaining: 47.1s\n",
      "599:\tlearn: 0.0933365\ttotal: 56.4s\tremaining: 47s\n",
      "600:\tlearn: 0.0932580\ttotal: 56.5s\tremaining: 46.9s\n",
      "601:\tlearn: 0.0931370\ttotal: 56.5s\tremaining: 46.8s\n",
      "602:\tlearn: 0.0930504\ttotal: 56.6s\tremaining: 46.6s\n",
      "603:\tlearn: 0.0929654\ttotal: 56.7s\tremaining: 46.5s\n",
      "604:\tlearn: 0.0928799\ttotal: 56.8s\tremaining: 46.5s\n",
      "605:\tlearn: 0.0927211\ttotal: 56.8s\tremaining: 46.3s\n",
      "606:\tlearn: 0.0925855\ttotal: 56.9s\tremaining: 46.2s\n",
      "607:\tlearn: 0.0925193\ttotal: 57s\tremaining: 46.1s\n",
      "608:\tlearn: 0.0924547\ttotal: 57.2s\tremaining: 46.1s\n",
      "609:\tlearn: 0.0923157\ttotal: 57.2s\tremaining: 46s\n",
      "610:\tlearn: 0.0922389\ttotal: 57.3s\tremaining: 45.9s\n",
      "611:\tlearn: 0.0920814\ttotal: 57.4s\tremaining: 45.8s\n",
      "612:\tlearn: 0.0919667\ttotal: 57.5s\tremaining: 45.7s\n",
      "613:\tlearn: 0.0918453\ttotal: 57.5s\tremaining: 45.6s\n",
      "614:\tlearn: 0.0917774\ttotal: 57.6s\tremaining: 45.4s\n",
      "615:\tlearn: 0.0916887\ttotal: 57.7s\tremaining: 45.3s\n",
      "616:\tlearn: 0.0915600\ttotal: 57.8s\tremaining: 45.2s\n",
      "617:\tlearn: 0.0914194\ttotal: 57.9s\tremaining: 45.1s\n",
      "618:\tlearn: 0.0913688\ttotal: 58s\tremaining: 45s\n",
      "619:\tlearn: 0.0912843\ttotal: 58s\tremaining: 44.9s\n",
      "620:\tlearn: 0.0911848\ttotal: 58.2s\tremaining: 44.9s\n",
      "621:\tlearn: 0.0910921\ttotal: 58.3s\tremaining: 44.8s\n",
      "622:\tlearn: 0.0909892\ttotal: 58.4s\tremaining: 44.7s\n",
      "623:\tlearn: 0.0909040\ttotal: 58.5s\tremaining: 44.6s\n",
      "624:\tlearn: 0.0907775\ttotal: 58.7s\tremaining: 44.6s\n",
      "625:\tlearn: 0.0906504\ttotal: 58.8s\tremaining: 44.5s\n",
      "626:\tlearn: 0.0905062\ttotal: 58.9s\tremaining: 44.4s\n",
      "627:\tlearn: 0.0903731\ttotal: 59s\tremaining: 44.3s\n",
      "628:\tlearn: 0.0902067\ttotal: 59.1s\tremaining: 44.2s\n",
      "629:\tlearn: 0.0900856\ttotal: 59.2s\tremaining: 44.1s\n",
      "630:\tlearn: 0.0899881\ttotal: 59.3s\tremaining: 44s\n",
      "631:\tlearn: 0.0898807\ttotal: 59.3s\tremaining: 43.9s\n",
      "632:\tlearn: 0.0897529\ttotal: 59.4s\tremaining: 43.8s\n",
      "633:\tlearn: 0.0896939\ttotal: 59.5s\tremaining: 43.7s\n",
      "634:\tlearn: 0.0895597\ttotal: 59.6s\tremaining: 43.7s\n",
      "635:\tlearn: 0.0893776\ttotal: 59.7s\tremaining: 43.6s\n",
      "636:\tlearn: 0.0892885\ttotal: 59.8s\tremaining: 43.5s\n",
      "637:\tlearn: 0.0891256\ttotal: 59.9s\tremaining: 43.4s\n",
      "638:\tlearn: 0.0890509\ttotal: 60s\tremaining: 43.3s\n",
      "639:\tlearn: 0.0889843\ttotal: 1m\tremaining: 43.1s\n",
      "640:\tlearn: 0.0889029\ttotal: 1m\tremaining: 43s\n",
      "641:\tlearn: 0.0887810\ttotal: 1m\tremaining: 43s\n",
      "642:\tlearn: 0.0887137\ttotal: 1m\tremaining: 42.9s\n",
      "643:\tlearn: 0.0886436\ttotal: 1m\tremaining: 42.8s\n",
      "644:\tlearn: 0.0885694\ttotal: 1m\tremaining: 42.6s\n",
      "645:\tlearn: 0.0884396\ttotal: 1m\tremaining: 42.6s\n",
      "646:\tlearn: 0.0883666\ttotal: 1m\tremaining: 42.5s\n",
      "647:\tlearn: 0.0882446\ttotal: 1m\tremaining: 42.4s\n",
      "648:\tlearn: 0.0881322\ttotal: 1m\tremaining: 42.3s\n",
      "649:\tlearn: 0.0880380\ttotal: 1m\tremaining: 42.2s\n",
      "650:\tlearn: 0.0879112\ttotal: 1m 1s\tremaining: 42.1s\n",
      "651:\tlearn: 0.0878289\ttotal: 1m 1s\tremaining: 42s\n",
      "652:\tlearn: 0.0877307\ttotal: 1m 1s\tremaining: 41.9s\n",
      "653:\tlearn: 0.0875908\ttotal: 1m 1s\tremaining: 41.8s\n",
      "654:\tlearn: 0.0874813\ttotal: 1m 1s\tremaining: 41.7s\n",
      "655:\tlearn: 0.0873836\ttotal: 1m 1s\tremaining: 41.6s\n",
      "656:\tlearn: 0.0872928\ttotal: 1m 1s\tremaining: 41.6s\n",
      "657:\tlearn: 0.0871685\ttotal: 1m 1s\tremaining: 41.5s\n",
      "658:\tlearn: 0.0870447\ttotal: 1m 1s\tremaining: 41.4s\n",
      "659:\tlearn: 0.0869423\ttotal: 1m 2s\tremaining: 41.3s\n",
      "660:\tlearn: 0.0867675\ttotal: 1m 2s\tremaining: 41.2s\n",
      "661:\tlearn: 0.0866219\ttotal: 1m 2s\tremaining: 41.2s\n",
      "662:\tlearn: 0.0864959\ttotal: 1m 2s\tremaining: 41.1s\n",
      "663:\tlearn: 0.0863951\ttotal: 1m 2s\tremaining: 41s\n",
      "664:\tlearn: 0.0862611\ttotal: 1m 2s\tremaining: 40.9s\n",
      "665:\tlearn: 0.0861547\ttotal: 1m 2s\tremaining: 40.9s\n",
      "666:\tlearn: 0.0860598\ttotal: 1m 2s\tremaining: 40.9s\n",
      "667:\tlearn: 0.0859934\ttotal: 1m 3s\tremaining: 40.8s\n",
      "668:\tlearn: 0.0858908\ttotal: 1m 3s\tremaining: 40.7s\n",
      "669:\tlearn: 0.0857856\ttotal: 1m 3s\tremaining: 40.6s\n",
      "670:\tlearn: 0.0857205\ttotal: 1m 3s\tremaining: 40.5s\n",
      "671:\tlearn: 0.0856681\ttotal: 1m 3s\tremaining: 40.4s\n",
      "672:\tlearn: 0.0855491\ttotal: 1m 3s\tremaining: 40.3s\n",
      "673:\tlearn: 0.0854647\ttotal: 1m 3s\tremaining: 40.2s\n",
      "674:\tlearn: 0.0853766\ttotal: 1m 3s\tremaining: 40.1s\n",
      "675:\tlearn: 0.0852285\ttotal: 1m 3s\tremaining: 40s\n",
      "676:\tlearn: 0.0851351\ttotal: 1m 3s\tremaining: 40s\n",
      "677:\tlearn: 0.0850128\ttotal: 1m 4s\tremaining: 39.9s\n",
      "678:\tlearn: 0.0849255\ttotal: 1m 4s\tremaining: 39.8s\n",
      "679:\tlearn: 0.0848206\ttotal: 1m 4s\tremaining: 39.7s\n",
      "680:\tlearn: 0.0847361\ttotal: 1m 4s\tremaining: 39.6s\n",
      "681:\tlearn: 0.0846279\ttotal: 1m 4s\tremaining: 39.5s\n",
      "682:\tlearn: 0.0845188\ttotal: 1m 4s\tremaining: 39.5s\n",
      "683:\tlearn: 0.0844047\ttotal: 1m 4s\tremaining: 39.4s\n",
      "684:\tlearn: 0.0842913\ttotal: 1m 4s\tremaining: 39.3s\n",
      "685:\tlearn: 0.0841773\ttotal: 1m 4s\tremaining: 39.2s\n",
      "686:\tlearn: 0.0841209\ttotal: 1m 4s\tremaining: 39.1s\n",
      "687:\tlearn: 0.0840301\ttotal: 1m 5s\tremaining: 39s\n",
      "688:\tlearn: 0.0838598\ttotal: 1m 5s\tremaining: 38.9s\n",
      "689:\tlearn: 0.0837495\ttotal: 1m 5s\tremaining: 38.8s\n",
      "690:\tlearn: 0.0836574\ttotal: 1m 5s\tremaining: 38.7s\n",
      "691:\tlearn: 0.0835890\ttotal: 1m 5s\tremaining: 38.6s\n",
      "692:\tlearn: 0.0834486\ttotal: 1m 5s\tremaining: 38.5s\n",
      "693:\tlearn: 0.0833873\ttotal: 1m 5s\tremaining: 38.4s\n",
      "694:\tlearn: 0.0833335\ttotal: 1m 5s\tremaining: 38.3s\n",
      "695:\tlearn: 0.0832410\ttotal: 1m 5s\tremaining: 38.2s\n",
      "696:\tlearn: 0.0830888\ttotal: 1m 5s\tremaining: 38.1s\n",
      "697:\tlearn: 0.0829390\ttotal: 1m 5s\tremaining: 38s\n",
      "698:\tlearn: 0.0828295\ttotal: 1m 6s\tremaining: 37.9s\n",
      "699:\tlearn: 0.0826974\ttotal: 1m 6s\tremaining: 37.8s\n",
      "700:\tlearn: 0.0825915\ttotal: 1m 6s\tremaining: 37.7s\n",
      "701:\tlearn: 0.0825394\ttotal: 1m 6s\tremaining: 37.6s\n",
      "702:\tlearn: 0.0824826\ttotal: 1m 6s\tremaining: 37.5s\n",
      "703:\tlearn: 0.0824279\ttotal: 1m 6s\tremaining: 37.4s\n",
      "704:\tlearn: 0.0823667\ttotal: 1m 6s\tremaining: 37.3s\n",
      "705:\tlearn: 0.0822281\ttotal: 1m 6s\tremaining: 37.2s\n",
      "706:\tlearn: 0.0820999\ttotal: 1m 6s\tremaining: 37.1s\n",
      "707:\tlearn: 0.0819991\ttotal: 1m 6s\tremaining: 37s\n",
      "708:\tlearn: 0.0819210\ttotal: 1m 6s\tremaining: 36.9s\n",
      "709:\tlearn: 0.0818686\ttotal: 1m 6s\tremaining: 36.8s\n",
      "710:\tlearn: 0.0817890\ttotal: 1m 7s\tremaining: 36.7s\n",
      "711:\tlearn: 0.0816929\ttotal: 1m 7s\tremaining: 36.6s\n",
      "712:\tlearn: 0.0816428\ttotal: 1m 7s\tremaining: 36.5s\n",
      "713:\tlearn: 0.0815779\ttotal: 1m 7s\tremaining: 36.4s\n",
      "714:\tlearn: 0.0814558\ttotal: 1m 7s\tremaining: 36.3s\n",
      "715:\tlearn: 0.0813655\ttotal: 1m 7s\tremaining: 36.2s\n",
      "716:\tlearn: 0.0813000\ttotal: 1m 7s\tremaining: 36.1s\n",
      "717:\tlearn: 0.0811914\ttotal: 1m 7s\tremaining: 36s\n",
      "718:\tlearn: 0.0811346\ttotal: 1m 7s\tremaining: 35.9s\n",
      "719:\tlearn: 0.0810086\ttotal: 1m 7s\tremaining: 35.8s\n",
      "720:\tlearn: 0.0809015\ttotal: 1m 7s\tremaining: 35.7s\n",
      "721:\tlearn: 0.0808446\ttotal: 1m 7s\tremaining: 35.6s\n",
      "722:\tlearn: 0.0807389\ttotal: 1m 8s\tremaining: 35.5s\n",
      "723:\tlearn: 0.0806433\ttotal: 1m 8s\tremaining: 35.4s\n",
      "724:\tlearn: 0.0805826\ttotal: 1m 8s\tremaining: 35.3s\n",
      "725:\tlearn: 0.0804951\ttotal: 1m 8s\tremaining: 35.2s\n",
      "726:\tlearn: 0.0803660\ttotal: 1m 8s\tremaining: 35.1s\n",
      "727:\tlearn: 0.0802307\ttotal: 1m 8s\tremaining: 35s\n",
      "728:\tlearn: 0.0801636\ttotal: 1m 8s\tremaining: 34.9s\n",
      "729:\tlearn: 0.0800688\ttotal: 1m 8s\tremaining: 34.8s\n",
      "730:\tlearn: 0.0799989\ttotal: 1m 8s\tremaining: 34.7s\n",
      "731:\tlearn: 0.0799223\ttotal: 1m 8s\tremaining: 34.6s\n",
      "732:\tlearn: 0.0797820\ttotal: 1m 8s\tremaining: 34.5s\n",
      "733:\tlearn: 0.0796844\ttotal: 1m 8s\tremaining: 34.4s\n",
      "734:\tlearn: 0.0795617\ttotal: 1m 9s\tremaining: 34.3s\n",
      "735:\tlearn: 0.0794609\ttotal: 1m 9s\tremaining: 34.2s\n",
      "736:\tlearn: 0.0793740\ttotal: 1m 9s\tremaining: 34.1s\n",
      "737:\tlearn: 0.0793004\ttotal: 1m 9s\tremaining: 34s\n",
      "738:\tlearn: 0.0792160\ttotal: 1m 9s\tremaining: 33.9s\n",
      "739:\tlearn: 0.0791492\ttotal: 1m 9s\tremaining: 33.8s\n",
      "740:\tlearn: 0.0790508\ttotal: 1m 9s\tremaining: 33.7s\n",
      "741:\tlearn: 0.0789443\ttotal: 1m 9s\tremaining: 33.6s\n",
      "742:\tlearn: 0.0788944\ttotal: 1m 9s\tremaining: 33.5s\n",
      "743:\tlearn: 0.0788058\ttotal: 1m 9s\tremaining: 33.4s\n",
      "744:\tlearn: 0.0787143\ttotal: 1m 9s\tremaining: 33.3s\n",
      "745:\tlearn: 0.0785611\ttotal: 1m 9s\tremaining: 33.2s\n",
      "746:\tlearn: 0.0784548\ttotal: 1m 10s\tremaining: 33.1s\n",
      "747:\tlearn: 0.0784116\ttotal: 1m 10s\tremaining: 33s\n",
      "748:\tlearn: 0.0783648\ttotal: 1m 10s\tremaining: 32.9s\n",
      "749:\tlearn: 0.0782591\ttotal: 1m 10s\tremaining: 32.8s\n",
      "750:\tlearn: 0.0781719\ttotal: 1m 10s\tremaining: 32.7s\n",
      "751:\tlearn: 0.0779934\ttotal: 1m 10s\tremaining: 32.6s\n",
      "752:\tlearn: 0.0779129\ttotal: 1m 10s\tremaining: 32.5s\n",
      "753:\tlearn: 0.0778097\ttotal: 1m 10s\tremaining: 32.4s\n",
      "754:\tlearn: 0.0776941\ttotal: 1m 10s\tremaining: 32.3s\n",
      "755:\tlearn: 0.0775952\ttotal: 1m 10s\tremaining: 32.2s\n",
      "756:\tlearn: 0.0775284\ttotal: 1m 10s\tremaining: 32.1s\n",
      "757:\tlearn: 0.0774265\ttotal: 1m 10s\tremaining: 32s\n",
      "758:\tlearn: 0.0772871\ttotal: 1m 11s\tremaining: 31.9s\n",
      "759:\tlearn: 0.0772123\ttotal: 1m 11s\tremaining: 31.8s\n",
      "760:\tlearn: 0.0771084\ttotal: 1m 11s\tremaining: 31.7s\n",
      "761:\tlearn: 0.0770175\ttotal: 1m 11s\tremaining: 31.6s\n",
      "762:\tlearn: 0.0769263\ttotal: 1m 11s\tremaining: 31.5s\n",
      "763:\tlearn: 0.0768246\ttotal: 1m 11s\tremaining: 31.4s\n",
      "764:\tlearn: 0.0767240\ttotal: 1m 11s\tremaining: 31.3s\n",
      "765:\tlearn: 0.0766097\ttotal: 1m 11s\tremaining: 31.2s\n",
      "766:\tlearn: 0.0764782\ttotal: 1m 11s\tremaining: 31.1s\n",
      "767:\tlearn: 0.0764086\ttotal: 1m 11s\tremaining: 31s\n",
      "768:\tlearn: 0.0763154\ttotal: 1m 11s\tremaining: 30.9s\n",
      "769:\tlearn: 0.0762276\ttotal: 1m 11s\tremaining: 30.8s\n",
      "770:\tlearn: 0.0761298\ttotal: 1m 12s\tremaining: 30.7s\n",
      "771:\tlearn: 0.0760290\ttotal: 1m 12s\tremaining: 30.6s\n",
      "772:\tlearn: 0.0759316\ttotal: 1m 12s\tremaining: 30.5s\n",
      "773:\tlearn: 0.0758390\ttotal: 1m 12s\tremaining: 30.4s\n",
      "774:\tlearn: 0.0757412\ttotal: 1m 12s\tremaining: 30.3s\n",
      "775:\tlearn: 0.0756431\ttotal: 1m 12s\tremaining: 30.2s\n",
      "776:\tlearn: 0.0755682\ttotal: 1m 12s\tremaining: 30.1s\n",
      "777:\tlearn: 0.0754962\ttotal: 1m 12s\tremaining: 30s\n",
      "778:\tlearn: 0.0754173\ttotal: 1m 12s\tremaining: 29.9s\n",
      "779:\tlearn: 0.0753100\ttotal: 1m 12s\tremaining: 29.8s\n",
      "780:\tlearn: 0.0751937\ttotal: 1m 12s\tremaining: 29.8s\n",
      "781:\tlearn: 0.0751264\ttotal: 1m 12s\tremaining: 29.7s\n",
      "782:\tlearn: 0.0750820\ttotal: 1m 13s\tremaining: 29.6s\n",
      "783:\tlearn: 0.0749764\ttotal: 1m 13s\tremaining: 29.5s\n",
      "784:\tlearn: 0.0748921\ttotal: 1m 13s\tremaining: 29.4s\n",
      "785:\tlearn: 0.0747850\ttotal: 1m 13s\tremaining: 29.3s\n",
      "786:\tlearn: 0.0747043\ttotal: 1m 13s\tremaining: 29.2s\n",
      "787:\tlearn: 0.0745924\ttotal: 1m 13s\tremaining: 29.1s\n",
      "788:\tlearn: 0.0745084\ttotal: 1m 13s\tremaining: 29s\n",
      "789:\tlearn: 0.0744291\ttotal: 1m 13s\tremaining: 28.9s\n",
      "790:\tlearn: 0.0743078\ttotal: 1m 13s\tremaining: 28.8s\n",
      "791:\tlearn: 0.0742159\ttotal: 1m 13s\tremaining: 28.7s\n",
      "792:\tlearn: 0.0741335\ttotal: 1m 13s\tremaining: 28.6s\n",
      "793:\tlearn: 0.0740511\ttotal: 1m 13s\tremaining: 28.5s\n",
      "794:\tlearn: 0.0739488\ttotal: 1m 13s\tremaining: 28.4s\n",
      "795:\tlearn: 0.0738409\ttotal: 1m 13s\tremaining: 28.3s\n",
      "796:\tlearn: 0.0737757\ttotal: 1m 14s\tremaining: 28.2s\n",
      "797:\tlearn: 0.0736930\ttotal: 1m 14s\tremaining: 28.1s\n",
      "798:\tlearn: 0.0735858\ttotal: 1m 14s\tremaining: 28s\n",
      "799:\tlearn: 0.0734985\ttotal: 1m 14s\tremaining: 27.9s\n",
      "800:\tlearn: 0.0734000\ttotal: 1m 14s\tremaining: 27.8s\n",
      "801:\tlearn: 0.0733392\ttotal: 1m 14s\tremaining: 27.7s\n",
      "802:\tlearn: 0.0732232\ttotal: 1m 14s\tremaining: 27.6s\n",
      "803:\tlearn: 0.0731089\ttotal: 1m 14s\tremaining: 27.5s\n",
      "804:\tlearn: 0.0729810\ttotal: 1m 14s\tremaining: 27.4s\n",
      "805:\tlearn: 0.0728718\ttotal: 1m 14s\tremaining: 27.3s\n",
      "806:\tlearn: 0.0727476\ttotal: 1m 14s\tremaining: 27.2s\n",
      "807:\tlearn: 0.0726452\ttotal: 1m 14s\tremaining: 27.1s\n",
      "808:\tlearn: 0.0725493\ttotal: 1m 14s\tremaining: 26.9s\n",
      "809:\tlearn: 0.0724712\ttotal: 1m 14s\tremaining: 26.8s\n",
      "810:\tlearn: 0.0723802\ttotal: 1m 15s\tremaining: 26.7s\n",
      "811:\tlearn: 0.0723070\ttotal: 1m 15s\tremaining: 26.6s\n",
      "812:\tlearn: 0.0722348\ttotal: 1m 15s\tremaining: 26.5s\n",
      "813:\tlearn: 0.0721739\ttotal: 1m 15s\tremaining: 26.4s\n",
      "814:\tlearn: 0.0720861\ttotal: 1m 15s\tremaining: 26.3s\n",
      "815:\tlearn: 0.0720467\ttotal: 1m 15s\tremaining: 26.2s\n",
      "816:\tlearn: 0.0719492\ttotal: 1m 15s\tremaining: 26.1s\n",
      "817:\tlearn: 0.0718443\ttotal: 1m 15s\tremaining: 26s\n",
      "818:\tlearn: 0.0717827\ttotal: 1m 15s\tremaining: 26s\n",
      "819:\tlearn: 0.0716959\ttotal: 1m 15s\tremaining: 25.9s\n",
      "820:\tlearn: 0.0716488\ttotal: 1m 15s\tremaining: 25.8s\n",
      "821:\tlearn: 0.0716103\ttotal: 1m 15s\tremaining: 25.6s\n",
      "822:\tlearn: 0.0715314\ttotal: 1m 15s\tremaining: 25.6s\n",
      "823:\tlearn: 0.0714676\ttotal: 1m 16s\tremaining: 25.5s\n",
      "824:\tlearn: 0.0713737\ttotal: 1m 16s\tremaining: 25.4s\n",
      "825:\tlearn: 0.0712832\ttotal: 1m 16s\tremaining: 25.3s\n",
      "826:\tlearn: 0.0712265\ttotal: 1m 16s\tremaining: 25.2s\n",
      "827:\tlearn: 0.0711768\ttotal: 1m 16s\tremaining: 25.1s\n",
      "828:\tlearn: 0.0711186\ttotal: 1m 16s\tremaining: 25s\n",
      "829:\tlearn: 0.0710133\ttotal: 1m 16s\tremaining: 24.9s\n",
      "830:\tlearn: 0.0709235\ttotal: 1m 16s\tremaining: 24.8s\n",
      "831:\tlearn: 0.0708504\ttotal: 1m 16s\tremaining: 24.7s\n",
      "832:\tlearn: 0.0708016\ttotal: 1m 16s\tremaining: 24.6s\n",
      "833:\tlearn: 0.0707307\ttotal: 1m 16s\tremaining: 24.5s\n",
      "834:\tlearn: 0.0706600\ttotal: 1m 16s\tremaining: 24.4s\n",
      "835:\tlearn: 0.0705536\ttotal: 1m 17s\tremaining: 24.3s\n",
      "836:\tlearn: 0.0704250\ttotal: 1m 17s\tremaining: 24.2s\n",
      "837:\tlearn: 0.0703320\ttotal: 1m 17s\tremaining: 24.1s\n",
      "838:\tlearn: 0.0702058\ttotal: 1m 17s\tremaining: 24s\n",
      "839:\tlearn: 0.0701452\ttotal: 1m 17s\tremaining: 23.9s\n",
      "840:\tlearn: 0.0700772\ttotal: 1m 17s\tremaining: 23.8s\n",
      "841:\tlearn: 0.0699947\ttotal: 1m 17s\tremaining: 23.7s\n",
      "842:\tlearn: 0.0699234\ttotal: 1m 17s\tremaining: 23.6s\n",
      "843:\tlearn: 0.0698117\ttotal: 1m 17s\tremaining: 23.5s\n",
      "844:\tlearn: 0.0697119\ttotal: 1m 17s\tremaining: 23.5s\n",
      "845:\tlearn: 0.0696485\ttotal: 1m 17s\tremaining: 23.4s\n",
      "846:\tlearn: 0.0695334\ttotal: 1m 17s\tremaining: 23.3s\n",
      "847:\tlearn: 0.0694375\ttotal: 1m 17s\tremaining: 23.2s\n",
      "848:\tlearn: 0.0693673\ttotal: 1m 18s\tremaining: 23.1s\n",
      "849:\tlearn: 0.0692839\ttotal: 1m 18s\tremaining: 23s\n",
      "850:\tlearn: 0.0691772\ttotal: 1m 18s\tremaining: 22.9s\n",
      "851:\tlearn: 0.0691469\ttotal: 1m 18s\tremaining: 22.8s\n",
      "852:\tlearn: 0.0690706\ttotal: 1m 18s\tremaining: 22.7s\n",
      "853:\tlearn: 0.0689890\ttotal: 1m 18s\tremaining: 22.6s\n",
      "854:\tlearn: 0.0688892\ttotal: 1m 18s\tremaining: 22.5s\n",
      "855:\tlearn: 0.0688488\ttotal: 1m 18s\tremaining: 22.4s\n",
      "856:\tlearn: 0.0687453\ttotal: 1m 18s\tremaining: 22.3s\n",
      "857:\tlearn: 0.0686649\ttotal: 1m 18s\tremaining: 22.2s\n",
      "858:\tlearn: 0.0686062\ttotal: 1m 18s\tremaining: 22.1s\n",
      "859:\tlearn: 0.0685637\ttotal: 1m 18s\tremaining: 22s\n",
      "860:\tlearn: 0.0685050\ttotal: 1m 18s\tremaining: 21.9s\n",
      "861:\tlearn: 0.0684440\ttotal: 1m 18s\tremaining: 21.8s\n",
      "862:\tlearn: 0.0683382\ttotal: 1m 19s\tremaining: 21.7s\n",
      "863:\tlearn: 0.0682329\ttotal: 1m 19s\tremaining: 21.6s\n",
      "864:\tlearn: 0.0681659\ttotal: 1m 19s\tremaining: 21.5s\n",
      "865:\tlearn: 0.0680451\ttotal: 1m 19s\tremaining: 21.4s\n",
      "866:\tlearn: 0.0679742\ttotal: 1m 19s\tremaining: 21.3s\n",
      "867:\tlearn: 0.0679064\ttotal: 1m 19s\tremaining: 21.2s\n",
      "868:\tlearn: 0.0678020\ttotal: 1m 19s\tremaining: 21.1s\n",
      "869:\tlearn: 0.0677380\ttotal: 1m 19s\tremaining: 21s\n",
      "870:\tlearn: 0.0676378\ttotal: 1m 19s\tremaining: 20.9s\n",
      "871:\tlearn: 0.0675611\ttotal: 1m 19s\tremaining: 20.9s\n",
      "872:\tlearn: 0.0675201\ttotal: 1m 19s\tremaining: 20.8s\n",
      "873:\tlearn: 0.0673976\ttotal: 1m 19s\tremaining: 20.7s\n",
      "874:\tlearn: 0.0673394\ttotal: 1m 19s\tremaining: 20.6s\n",
      "875:\tlearn: 0.0672719\ttotal: 1m 20s\tremaining: 20.5s\n",
      "876:\tlearn: 0.0671940\ttotal: 1m 20s\tremaining: 20.4s\n",
      "877:\tlearn: 0.0671386\ttotal: 1m 20s\tremaining: 20.3s\n",
      "878:\tlearn: 0.0670401\ttotal: 1m 20s\tremaining: 20.2s\n",
      "879:\tlearn: 0.0669360\ttotal: 1m 20s\tremaining: 20.1s\n",
      "880:\tlearn: 0.0668035\ttotal: 1m 20s\tremaining: 20s\n",
      "881:\tlearn: 0.0667007\ttotal: 1m 20s\tremaining: 19.9s\n",
      "882:\tlearn: 0.0666344\ttotal: 1m 20s\tremaining: 19.8s\n",
      "883:\tlearn: 0.0665977\ttotal: 1m 20s\tremaining: 19.7s\n",
      "884:\tlearn: 0.0665291\ttotal: 1m 20s\tremaining: 19.6s\n",
      "885:\tlearn: 0.0664965\ttotal: 1m 20s\tremaining: 19.5s\n",
      "886:\tlearn: 0.0664121\ttotal: 1m 20s\tremaining: 19.4s\n",
      "887:\tlearn: 0.0663468\ttotal: 1m 20s\tremaining: 19.3s\n",
      "888:\tlearn: 0.0662292\ttotal: 1m 21s\tremaining: 19.2s\n",
      "889:\tlearn: 0.0661286\ttotal: 1m 21s\tremaining: 19.1s\n",
      "890:\tlearn: 0.0660669\ttotal: 1m 21s\tremaining: 19s\n",
      "891:\tlearn: 0.0660045\ttotal: 1m 21s\tremaining: 18.9s\n",
      "892:\tlearn: 0.0659181\ttotal: 1m 21s\tremaining: 18.8s\n",
      "893:\tlearn: 0.0658393\ttotal: 1m 21s\tremaining: 18.7s\n",
      "894:\tlearn: 0.0657999\ttotal: 1m 21s\tremaining: 18.7s\n",
      "895:\tlearn: 0.0657336\ttotal: 1m 21s\tremaining: 18.6s\n",
      "896:\tlearn: 0.0656537\ttotal: 1m 21s\tremaining: 18.5s\n",
      "897:\tlearn: 0.0655727\ttotal: 1m 21s\tremaining: 18.4s\n",
      "898:\tlearn: 0.0654817\ttotal: 1m 21s\tremaining: 18.3s\n",
      "899:\tlearn: 0.0653955\ttotal: 1m 21s\tremaining: 18.2s\n",
      "900:\tlearn: 0.0653413\ttotal: 1m 21s\tremaining: 18.1s\n",
      "901:\tlearn: 0.0652915\ttotal: 1m 21s\tremaining: 18s\n",
      "902:\tlearn: 0.0652059\ttotal: 1m 22s\tremaining: 17.9s\n",
      "903:\tlearn: 0.0651153\ttotal: 1m 22s\tremaining: 17.8s\n",
      "904:\tlearn: 0.0650360\ttotal: 1m 22s\tremaining: 17.7s\n",
      "905:\tlearn: 0.0649643\ttotal: 1m 22s\tremaining: 17.6s\n",
      "906:\tlearn: 0.0648813\ttotal: 1m 22s\tremaining: 17.5s\n",
      "907:\tlearn: 0.0648085\ttotal: 1m 22s\tremaining: 17.4s\n",
      "908:\tlearn: 0.0647431\ttotal: 1m 22s\tremaining: 17.3s\n",
      "909:\tlearn: 0.0646411\ttotal: 1m 22s\tremaining: 17.2s\n",
      "910:\tlearn: 0.0645615\ttotal: 1m 22s\tremaining: 17.1s\n",
      "911:\tlearn: 0.0644928\ttotal: 1m 22s\tremaining: 17s\n",
      "912:\tlearn: 0.0643950\ttotal: 1m 22s\tremaining: 16.9s\n",
      "913:\tlearn: 0.0643089\ttotal: 1m 22s\tremaining: 16.8s\n",
      "914:\tlearn: 0.0642082\ttotal: 1m 22s\tremaining: 16.8s\n",
      "915:\tlearn: 0.0641565\ttotal: 1m 22s\tremaining: 16.7s\n",
      "916:\tlearn: 0.0640985\ttotal: 1m 22s\tremaining: 16.6s\n",
      "917:\tlearn: 0.0640317\ttotal: 1m 23s\tremaining: 16.5s\n",
      "918:\tlearn: 0.0639473\ttotal: 1m 23s\tremaining: 16.4s\n",
      "919:\tlearn: 0.0638840\ttotal: 1m 23s\tremaining: 16.3s\n",
      "920:\tlearn: 0.0638228\ttotal: 1m 23s\tremaining: 16.2s\n",
      "921:\tlearn: 0.0637629\ttotal: 1m 23s\tremaining: 16.1s\n",
      "922:\tlearn: 0.0637031\ttotal: 1m 23s\tremaining: 16s\n",
      "923:\tlearn: 0.0636436\ttotal: 1m 23s\tremaining: 15.9s\n",
      "924:\tlearn: 0.0635776\ttotal: 1m 23s\tremaining: 15.8s\n",
      "925:\tlearn: 0.0635351\ttotal: 1m 23s\tremaining: 15.7s\n",
      "926:\tlearn: 0.0634476\ttotal: 1m 23s\tremaining: 15.6s\n",
      "927:\tlearn: 0.0634024\ttotal: 1m 23s\tremaining: 15.5s\n",
      "928:\tlearn: 0.0633211\ttotal: 1m 23s\tremaining: 15.4s\n",
      "929:\tlearn: 0.0632552\ttotal: 1m 23s\tremaining: 15.3s\n",
      "930:\tlearn: 0.0631605\ttotal: 1m 24s\tremaining: 15.3s\n",
      "931:\tlearn: 0.0630582\ttotal: 1m 24s\tremaining: 15.2s\n",
      "932:\tlearn: 0.0629966\ttotal: 1m 24s\tremaining: 15.1s\n",
      "933:\tlearn: 0.0629381\ttotal: 1m 24s\tremaining: 15s\n",
      "934:\tlearn: 0.0628520\ttotal: 1m 24s\tremaining: 14.9s\n",
      "935:\tlearn: 0.0628033\ttotal: 1m 24s\tremaining: 14.8s\n",
      "936:\tlearn: 0.0627462\ttotal: 1m 24s\tremaining: 14.7s\n",
      "937:\tlearn: 0.0626656\ttotal: 1m 24s\tremaining: 14.6s\n",
      "938:\tlearn: 0.0625943\ttotal: 1m 24s\tremaining: 14.5s\n",
      "939:\tlearn: 0.0625107\ttotal: 1m 24s\tremaining: 14.4s\n",
      "940:\tlearn: 0.0624823\ttotal: 1m 24s\tremaining: 14.3s\n",
      "941:\tlearn: 0.0623958\ttotal: 1m 24s\tremaining: 14.2s\n",
      "942:\tlearn: 0.0622985\ttotal: 1m 24s\tremaining: 14.1s\n",
      "943:\tlearn: 0.0622194\ttotal: 1m 25s\tremaining: 14.1s\n",
      "944:\tlearn: 0.0621448\ttotal: 1m 25s\tremaining: 14s\n",
      "945:\tlearn: 0.0620616\ttotal: 1m 25s\tremaining: 13.9s\n",
      "946:\tlearn: 0.0619579\ttotal: 1m 25s\tremaining: 13.8s\n",
      "947:\tlearn: 0.0618895\ttotal: 1m 25s\tremaining: 13.7s\n",
      "948:\tlearn: 0.0618330\ttotal: 1m 25s\tremaining: 13.6s\n",
      "949:\tlearn: 0.0617795\ttotal: 1m 25s\tremaining: 13.5s\n",
      "950:\tlearn: 0.0616977\ttotal: 1m 25s\tremaining: 13.4s\n",
      "951:\tlearn: 0.0616451\ttotal: 1m 25s\tremaining: 13.3s\n",
      "952:\tlearn: 0.0615958\ttotal: 1m 25s\tremaining: 13.2s\n",
      "953:\tlearn: 0.0615368\ttotal: 1m 25s\tremaining: 13.1s\n",
      "954:\tlearn: 0.0614516\ttotal: 1m 25s\tremaining: 13s\n",
      "955:\tlearn: 0.0613591\ttotal: 1m 26s\tremaining: 13s\n",
      "956:\tlearn: 0.0612864\ttotal: 1m 26s\tremaining: 12.9s\n",
      "957:\tlearn: 0.0611893\ttotal: 1m 26s\tremaining: 12.8s\n",
      "958:\tlearn: 0.0611374\ttotal: 1m 26s\tremaining: 12.7s\n",
      "959:\tlearn: 0.0610968\ttotal: 1m 26s\tremaining: 12.6s\n",
      "960:\tlearn: 0.0610093\ttotal: 1m 26s\tremaining: 12.5s\n",
      "961:\tlearn: 0.0609599\ttotal: 1m 26s\tremaining: 12.4s\n",
      "962:\tlearn: 0.0608879\ttotal: 1m 26s\tremaining: 12.3s\n",
      "963:\tlearn: 0.0608265\ttotal: 1m 26s\tremaining: 12.2s\n",
      "964:\tlearn: 0.0607575\ttotal: 1m 26s\tremaining: 12.1s\n",
      "965:\tlearn: 0.0606797\ttotal: 1m 26s\tremaining: 12s\n",
      "966:\tlearn: 0.0606130\ttotal: 1m 26s\tremaining: 11.9s\n",
      "967:\tlearn: 0.0605494\ttotal: 1m 26s\tremaining: 11.8s\n",
      "968:\tlearn: 0.0605047\ttotal: 1m 26s\tremaining: 11.8s\n",
      "969:\tlearn: 0.0604394\ttotal: 1m 27s\tremaining: 11.7s\n",
      "970:\tlearn: 0.0603754\ttotal: 1m 27s\tremaining: 11.6s\n",
      "971:\tlearn: 0.0603143\ttotal: 1m 27s\tremaining: 11.5s\n",
      "972:\tlearn: 0.0602663\ttotal: 1m 27s\tremaining: 11.4s\n",
      "973:\tlearn: 0.0602083\ttotal: 1m 27s\tremaining: 11.3s\n",
      "974:\tlearn: 0.0601315\ttotal: 1m 27s\tremaining: 11.2s\n",
      "975:\tlearn: 0.0600480\ttotal: 1m 27s\tremaining: 11.1s\n",
      "976:\tlearn: 0.0600170\ttotal: 1m 27s\tremaining: 11s\n",
      "977:\tlearn: 0.0599524\ttotal: 1m 27s\tremaining: 11s\n",
      "978:\tlearn: 0.0598736\ttotal: 1m 27s\tremaining: 10.9s\n",
      "979:\tlearn: 0.0598003\ttotal: 1m 27s\tremaining: 10.8s\n",
      "980:\tlearn: 0.0597224\ttotal: 1m 28s\tremaining: 10.7s\n",
      "981:\tlearn: 0.0596711\ttotal: 1m 28s\tremaining: 10.6s\n",
      "982:\tlearn: 0.0595984\ttotal: 1m 28s\tremaining: 10.5s\n",
      "983:\tlearn: 0.0595144\ttotal: 1m 28s\tremaining: 10.4s\n",
      "984:\tlearn: 0.0594389\ttotal: 1m 28s\tremaining: 10.3s\n",
      "985:\tlearn: 0.0594129\ttotal: 1m 28s\tremaining: 10.2s\n",
      "986:\tlearn: 0.0593779\ttotal: 1m 28s\tremaining: 10.2s\n",
      "987:\tlearn: 0.0592988\ttotal: 1m 28s\tremaining: 10.1s\n",
      "988:\tlearn: 0.0592435\ttotal: 1m 28s\tremaining: 9.96s\n",
      "989:\tlearn: 0.0591793\ttotal: 1m 28s\tremaining: 9.87s\n",
      "990:\tlearn: 0.0591154\ttotal: 1m 28s\tremaining: 9.78s\n",
      "991:\tlearn: 0.0590510\ttotal: 1m 28s\tremaining: 9.69s\n",
      "992:\tlearn: 0.0589998\ttotal: 1m 29s\tremaining: 9.6s\n",
      "993:\tlearn: 0.0589122\ttotal: 1m 29s\tremaining: 9.51s\n",
      "994:\tlearn: 0.0588324\ttotal: 1m 29s\tremaining: 9.42s\n",
      "995:\tlearn: 0.0587609\ttotal: 1m 29s\tremaining: 9.34s\n",
      "996:\tlearn: 0.0587343\ttotal: 1m 29s\tremaining: 9.25s\n",
      "997:\tlearn: 0.0586647\ttotal: 1m 29s\tremaining: 9.15s\n",
      "998:\tlearn: 0.0586123\ttotal: 1m 29s\tremaining: 9.06s\n",
      "999:\tlearn: 0.0585312\ttotal: 1m 29s\tremaining: 8.97s\n",
      "1000:\tlearn: 0.0584553\ttotal: 1m 29s\tremaining: 8.89s\n",
      "1001:\tlearn: 0.0583481\ttotal: 1m 29s\tremaining: 8.8s\n",
      "1002:\tlearn: 0.0582856\ttotal: 1m 30s\tremaining: 8.71s\n",
      "1003:\tlearn: 0.0582392\ttotal: 1m 30s\tremaining: 8.62s\n",
      "1004:\tlearn: 0.0582025\ttotal: 1m 30s\tremaining: 8.53s\n",
      "1005:\tlearn: 0.0581544\ttotal: 1m 30s\tremaining: 8.44s\n",
      "1006:\tlearn: 0.0580893\ttotal: 1m 30s\tremaining: 8.34s\n",
      "1007:\tlearn: 0.0580077\ttotal: 1m 30s\tremaining: 8.25s\n",
      "1008:\tlearn: 0.0579724\ttotal: 1m 30s\tremaining: 8.16s\n",
      "1009:\tlearn: 0.0579184\ttotal: 1m 30s\tremaining: 8.07s\n",
      "1010:\tlearn: 0.0578497\ttotal: 1m 30s\tremaining: 7.98s\n",
      "1011:\tlearn: 0.0577944\ttotal: 1m 30s\tremaining: 7.89s\n",
      "1012:\tlearn: 0.0577509\ttotal: 1m 30s\tremaining: 7.8s\n",
      "1013:\tlearn: 0.0577018\ttotal: 1m 30s\tremaining: 7.71s\n",
      "1014:\tlearn: 0.0576184\ttotal: 1m 30s\tremaining: 7.62s\n",
      "1015:\tlearn: 0.0575550\ttotal: 1m 31s\tremaining: 7.53s\n",
      "1016:\tlearn: 0.0575046\ttotal: 1m 31s\tremaining: 7.43s\n",
      "1017:\tlearn: 0.0574154\ttotal: 1m 31s\tremaining: 7.34s\n",
      "1018:\tlearn: 0.0573583\ttotal: 1m 31s\tremaining: 7.25s\n",
      "1019:\tlearn: 0.0573135\ttotal: 1m 31s\tremaining: 7.16s\n",
      "1020:\tlearn: 0.0572211\ttotal: 1m 31s\tremaining: 7.07s\n",
      "1021:\tlearn: 0.0571812\ttotal: 1m 31s\tremaining: 6.98s\n",
      "1022:\tlearn: 0.0571056\ttotal: 1m 31s\tremaining: 6.89s\n",
      "1023:\tlearn: 0.0570502\ttotal: 1m 31s\tremaining: 6.8s\n",
      "1024:\tlearn: 0.0569745\ttotal: 1m 31s\tremaining: 6.71s\n",
      "1025:\tlearn: 0.0569375\ttotal: 1m 31s\tremaining: 6.62s\n",
      "1026:\tlearn: 0.0568880\ttotal: 1m 31s\tremaining: 6.53s\n",
      "1027:\tlearn: 0.0567992\ttotal: 1m 31s\tremaining: 6.44s\n",
      "1028:\tlearn: 0.0567826\ttotal: 1m 31s\tremaining: 6.35s\n",
      "1029:\tlearn: 0.0566995\ttotal: 1m 32s\tremaining: 6.25s\n",
      "1030:\tlearn: 0.0566417\ttotal: 1m 32s\tremaining: 6.17s\n",
      "1031:\tlearn: 0.0565521\ttotal: 1m 32s\tremaining: 6.07s\n",
      "1032:\tlearn: 0.0564620\ttotal: 1m 32s\tremaining: 5.98s\n",
      "1033:\tlearn: 0.0564267\ttotal: 1m 32s\tremaining: 5.89s\n",
      "1034:\tlearn: 0.0563631\ttotal: 1m 32s\tremaining: 5.8s\n",
      "1035:\tlearn: 0.0563288\ttotal: 1m 32s\tremaining: 5.71s\n",
      "1036:\tlearn: 0.0562829\ttotal: 1m 32s\tremaining: 5.63s\n",
      "1037:\tlearn: 0.0562202\ttotal: 1m 32s\tremaining: 5.54s\n",
      "1038:\tlearn: 0.0561332\ttotal: 1m 32s\tremaining: 5.45s\n",
      "1039:\tlearn: 0.0560555\ttotal: 1m 32s\tremaining: 5.36s\n",
      "1040:\tlearn: 0.0559623\ttotal: 1m 32s\tremaining: 5.27s\n",
      "1041:\tlearn: 0.0559115\ttotal: 1m 33s\tremaining: 5.18s\n",
      "1042:\tlearn: 0.0558057\ttotal: 1m 33s\tremaining: 5.09s\n",
      "1043:\tlearn: 0.0557709\ttotal: 1m 33s\tremaining: 5s\n",
      "1044:\tlearn: 0.0556965\ttotal: 1m 33s\tremaining: 4.91s\n",
      "1045:\tlearn: 0.0556303\ttotal: 1m 33s\tremaining: 4.82s\n",
      "1046:\tlearn: 0.0555903\ttotal: 1m 33s\tremaining: 4.72s\n",
      "1047:\tlearn: 0.0555439\ttotal: 1m 33s\tremaining: 4.63s\n",
      "1048:\tlearn: 0.0554650\ttotal: 1m 33s\tremaining: 4.55s\n",
      "1049:\tlearn: 0.0554245\ttotal: 1m 33s\tremaining: 4.46s\n",
      "1050:\tlearn: 0.0553247\ttotal: 1m 33s\tremaining: 4.37s\n",
      "1051:\tlearn: 0.0552903\ttotal: 1m 33s\tremaining: 4.28s\n",
      "1052:\tlearn: 0.0552292\ttotal: 1m 33s\tremaining: 4.19s\n",
      "1053:\tlearn: 0.0551635\ttotal: 1m 33s\tremaining: 4.1s\n",
      "1054:\tlearn: 0.0550748\ttotal: 1m 33s\tremaining: 4.01s\n",
      "1055:\tlearn: 0.0550256\ttotal: 1m 34s\tremaining: 3.92s\n",
      "1056:\tlearn: 0.0549789\ttotal: 1m 34s\tremaining: 3.83s\n",
      "1057:\tlearn: 0.0549229\ttotal: 1m 34s\tremaining: 3.74s\n",
      "1058:\tlearn: 0.0548165\ttotal: 1m 34s\tremaining: 3.65s\n",
      "1059:\tlearn: 0.0547496\ttotal: 1m 34s\tremaining: 3.56s\n",
      "1060:\tlearn: 0.0546987\ttotal: 1m 34s\tremaining: 3.47s\n",
      "1061:\tlearn: 0.0546607\ttotal: 1m 34s\tremaining: 3.38s\n",
      "1062:\tlearn: 0.0546076\ttotal: 1m 34s\tremaining: 3.29s\n",
      "1063:\tlearn: 0.0545521\ttotal: 1m 34s\tremaining: 3.2s\n",
      "1064:\tlearn: 0.0544929\ttotal: 1m 34s\tremaining: 3.11s\n",
      "1065:\tlearn: 0.0544573\ttotal: 1m 34s\tremaining: 3.02s\n",
      "1066:\tlearn: 0.0543907\ttotal: 1m 34s\tremaining: 2.93s\n",
      "1067:\tlearn: 0.0543462\ttotal: 1m 34s\tremaining: 2.84s\n",
      "1068:\tlearn: 0.0542927\ttotal: 1m 34s\tremaining: 2.75s\n",
      "1069:\tlearn: 0.0542517\ttotal: 1m 35s\tremaining: 2.66s\n",
      "1070:\tlearn: 0.0541871\ttotal: 1m 35s\tremaining: 2.58s\n",
      "1071:\tlearn: 0.0541190\ttotal: 1m 35s\tremaining: 2.49s\n",
      "1072:\tlearn: 0.0540561\ttotal: 1m 35s\tremaining: 2.4s\n",
      "1073:\tlearn: 0.0539503\ttotal: 1m 35s\tremaining: 2.31s\n",
      "1074:\tlearn: 0.0538836\ttotal: 1m 35s\tremaining: 2.22s\n",
      "1075:\tlearn: 0.0538508\ttotal: 1m 35s\tremaining: 2.13s\n",
      "1076:\tlearn: 0.0537917\ttotal: 1m 35s\tremaining: 2.04s\n",
      "1077:\tlearn: 0.0537278\ttotal: 1m 35s\tremaining: 1.95s\n",
      "1078:\tlearn: 0.0536513\ttotal: 1m 35s\tremaining: 1.86s\n",
      "1079:\tlearn: 0.0536167\ttotal: 1m 35s\tremaining: 1.77s\n",
      "1080:\tlearn: 0.0535451\ttotal: 1m 35s\tremaining: 1.69s\n",
      "1081:\tlearn: 0.0534756\ttotal: 1m 36s\tremaining: 1.6s\n",
      "1082:\tlearn: 0.0533931\ttotal: 1m 36s\tremaining: 1.51s\n",
      "1083:\tlearn: 0.0533212\ttotal: 1m 36s\tremaining: 1.42s\n",
      "1084:\tlearn: 0.0532587\ttotal: 1m 36s\tremaining: 1.33s\n",
      "1085:\tlearn: 0.0532005\ttotal: 1m 36s\tremaining: 1.24s\n",
      "1086:\tlearn: 0.0531412\ttotal: 1m 36s\tremaining: 1.15s\n",
      "1087:\tlearn: 0.0530509\ttotal: 1m 36s\tremaining: 1.06s\n",
      "1088:\tlearn: 0.0529852\ttotal: 1m 36s\tremaining: 975ms\n",
      "1089:\tlearn: 0.0529035\ttotal: 1m 36s\tremaining: 887ms\n",
      "1090:\tlearn: 0.0528057\ttotal: 1m 36s\tremaining: 798ms\n",
      "1091:\tlearn: 0.0527403\ttotal: 1m 36s\tremaining: 709ms\n",
      "1092:\tlearn: 0.0526875\ttotal: 1m 36s\tremaining: 620ms\n",
      "1093:\tlearn: 0.0526403\ttotal: 1m 36s\tremaining: 531ms\n",
      "1094:\tlearn: 0.0526043\ttotal: 1m 36s\tremaining: 443ms\n",
      "1095:\tlearn: 0.0525373\ttotal: 1m 37s\tremaining: 354ms\n",
      "1096:\tlearn: 0.0524973\ttotal: 1m 37s\tremaining: 266ms\n",
      "1097:\tlearn: 0.0524427\ttotal: 1m 37s\tremaining: 177ms\n",
      "1098:\tlearn: 0.0523926\ttotal: 1m 37s\tremaining: 88.5ms\n",
      "1099:\tlearn: 0.0523363\ttotal: 1m 37s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x263bf9a6230>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostClassifier(**modelCAT.best_params_, learning_rate=0.1)\n",
    "cb.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878076121260457\n"
     ]
    }
   ],
   "source": [
    "#now predict X_test using the modelCAT best features\n",
    "md_probs = cb.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(md_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8846443893745769\n"
     ]
    }
   ],
   "source": [
    "#now predict X_test using the modelCAT best features\n",
    "md_probs = modelCAT.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(md_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_pred = modelCAT.predict_proba(onehotTest)\n",
    "hospital_death = y_new_pred[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsBOOTSTRAP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_pred = cb.predict_proba(onehotTest)\n",
    "hospital_death = y_new_pred[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsCAT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importance = cb.get_feature_importance()\n",
    "\n",
    "# Create a dataframe with feature importance scores\n",
    "df_feature_importance = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the dataframe by importance score\n",
    "df_feature_importance = df_feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance scores as a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_feature_importance['Feature'], df_feature_importance['Importance'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Feature Importance Scores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 102 but corresponding boolean dimension is 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hamza\\Documents\\7th Sem\\IDM\\Challenge 1\\C1ptNormalization.ipynb Cell 42\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#only get columns greater than feature importnace 2\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m important_features \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39;49mcolumns[cb\u001b[39m.\u001b[39;49mfeature_importances_ \u001b[39m>\u001b[39;49m \u001b[39m2\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m important_featurestest\u001b[39m=\u001b[39monehotTest\u001b[39m.\u001b[39mcolumns[cb\u001b[39m.\u001b[39mfeature_importances_ \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/C1ptNormalization.ipynb#X63sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m important_featuresXtest\u001b[39m=\u001b[39mX_test\u001b[39m.\u001b[39mcolumns[cb\u001b[39m.\u001b[39mfeature_importances_ \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:5339\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5336\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5337\u001b[0m         key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m-> 5339\u001b[0m result \u001b[39m=\u001b[39m getitem(key)\n\u001b[0;32m   5340\u001b[0m \u001b[39m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[0;32m   5341\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 102 but corresponding boolean dimension is 12"
     ]
    }
   ],
   "source": [
    "#only get columns greater than feature importnace 2\n",
    "important_features = X_train.columns[cb.feature_importances_ > 2]\n",
    "important_featurestest=onehotTest.columns[cb.feature_importances_ > 2]\n",
    "important_featuresXtest=X_test.columns[cb.feature_importances_ > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost  :  0.8730837003377538\n",
      "Total time CB:  346.19266963005066\n"
     ]
    }
   ],
   "source": [
    "cb = CatBoostClassifier(iterations=200, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=False)\n",
    "#now fit cb on importn feautres\n",
    "cb.fit(X_train[important_features],y_train)\n",
    "md_probs = cb.predict_proba(X_test[important_featuresXtest])\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Cat Boost\", \" : \", md_auc)\n",
    "#record the end time\n",
    "end_time = time.time()\n",
    "#calculate the total time\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time CB: \", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost  :  0.8837160313573902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create a pipeline with scaling and CatBoostClassifier\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('classifier', CatBoostClassifier(iterations=250, depth=4, learning_rate=0.1, loss_function='Logloss', verbose=False))])\n",
    "\n",
    "# fit the pipeline on training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# predict on test data\n",
    "md_probs = pipe.predict_proba(X_test)\n",
    "md_probs = md_probs[:,1]\n",
    "md_auc = roc_auc_score(y_test, md_probs)\n",
    "print(\"Cat Boost\", \" : \", md_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
