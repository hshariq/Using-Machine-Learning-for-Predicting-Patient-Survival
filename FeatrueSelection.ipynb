{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "Train = pd.read_csv(\"Data/train.csv\")\n",
    "Test = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train.drop('gender', axis=1, inplace=True)\n",
    "# Test.drop('gender', axis=1, inplace=True)\n",
    "# Train.drop('apache_3j_bodysystem', axis=1, inplace=True)\n",
    "# Test.drop('apache_3j_bodysystem', axis=1, inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#normalise Train['pre_icu_los_days']\n",
    "Train['pre_icu_los_days'] = np.log1p(Train['pre_icu_los_days'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "\n",
    "#normalise Train['pre_icu_los_days']\n",
    "Test['pre_icu_los_days'] = np.log1p(Test['pre_icu_los_days'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#simialrly normalise apache_2_diagnosis\n",
    "Train['apache_2_diagnosis'] = np.log1p(Train['apache_2_diagnosis'])\n",
    "Test['apache_2_diagnosis'] = np.log1p(Test['apache_2_diagnosis'])\n",
    "#do for apache_3j_diagnosis as well for both train and test\n",
    "Train['apache_3j_diagnosis'] = np.log1p(Train['apache_3j_diagnosis'])\n",
    "#do for test as well\n",
    "Test['apache_3j_diagnosis'] = np.log1p(Test['apache_3j_diagnosis'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for resprate_apache as well\n",
    "Train['d1_resprate_max'] = np.log1p(Train['d1_resprate_max'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for test as well\n",
    "Test['d1_resprate_max'] = np.log1p(Test['d1_resprate_max'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for temp_apache as well\n",
    "Train['temp_apache'] = np.log1p(Train['temp_apache'])\n",
    "#do for test as well\n",
    "Test['temp_apache'] = np.log1p(Test['temp_apache'])\n",
    "#do foor d1_resprate_max as well\n",
    "Train['d1_resprate_max'] = np.log1p(Train['d1_resprate_max'])\n",
    "#do for test as well\n",
    "Test['d1_resprate_max'] = np.log1p(Test['d1_resprate_max'])\n",
    "#do for d1_temp_min\n",
    "Train['d1_temp_min'] = np.log1p(Train['d1_temp_min'])\n",
    "#do for test as well\n",
    "Test['d1_temp_min'] = np.log1p(Test['d1_temp_min'])\n",
    "#do foe h1_spo2_max\n",
    "Train['h1_spo2_max'] = np.log1p(Train['h1_spo2_max'])\n",
    "#do for test as well\n",
    "Test['h1_spo2_max'] = np.log1p(Test['h1_spo2_max'])\n",
    "#do for h1_spo2_min\n",
    "Train['h1_spo2_min'] = np.log1p(Train['h1_spo2_min'])\n",
    "#do for test as well\n",
    "Test['h1_spo2_min'] = np.log1p(Test['h1_spo2_min'])\n",
    "#do for d1_glucose_max\n",
    "Train['d1_glucose_max'] = np.log1p(Train['d1_glucose_max'])\n",
    "#do for test as well\n",
    "Test['d1_glucose_max'] = np.log1p(Test['d1_glucose_max'])\n",
    "#since all these r heavily skewed andaffected by the outliers we will fill them using median imputation\n",
    "\n",
    "# fill null values with median for temp_apache\n",
    "Train['temp_apache'].fillna(Train['temp_apache'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for d1_potassium_max\n",
    "Train['d1_potassium_max'].fillna(Train['d1_potassium_max'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_hospital_death_prob\n",
    "Train['apache_4a_hospital_death_prob'].fillna(Train['apache_4a_hospital_death_prob'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_icu_death_prob\n",
    "Train['apache_4a_icu_death_prob'].fillna(Train['apache_4a_icu_death_prob'].median(), inplace=True)\n",
    "#since all these r heavily skewed andaffected by the outliers we will fill them using median imputation\n",
    "\n",
    "Test['temp_apache'].fillna(Test['temp_apache'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for d1_potassium_max\n",
    "Test['d1_potassium_max'].fillna(Test['d1_potassium_max'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_hospital_death_prob\n",
    "Test['apache_4a_hospital_death_prob'].fillna(Test['apache_4a_hospital_death_prob'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_icu_death_prob\n",
    "Test['apache_4a_icu_death_prob'].fillna(Test['apache_4a_icu_death_prob'].median(), inplace=True)\n",
    "\n",
    "# group the dataframe by apache_2_bodysystem and calculate the mean age for each group\n",
    "mean_age_by_bodysystem = Train.groupby('apache_2_bodysystem')['age'].mean()\n",
    "\n",
    "# define a function that takes a row of the dataframe as input and returns the mean age of the corresponding apache_2_bodysystem\n",
    "def fill_age(row):\n",
    "    if pd.isnull(row['age']):\n",
    "        if pd.isnull(row['apache_2_bodysystem']):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return mean_age_by_bodysystem[row['apache_2_bodysystem']]\n",
    "    else:\n",
    "        return row['age']\n",
    "\n",
    "# apply the function to each row of the dataframe and fill the missing age values with the corresponding mean age\n",
    "Train['age'] = Train.apply(fill_age, axis=1)\n",
    "\n",
    "# group the dataframe by apache_2_bodysystem and calculate the mean age for each group\n",
    "mean_age_by_bodysystem = Test.groupby('apache_2_bodysystem')['age'].mean()\n",
    "\n",
    "# define a function that takes a row of the dataframe as input and returns the mean age of the corresponding apache_2_bodysystem\n",
    "def fill_age(row):\n",
    "    if pd.isnull(row['age']):\n",
    "        if pd.isnull(row['apache_2_bodysystem']):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return mean_age_by_bodysystem[row['apache_2_bodysystem']]\n",
    "    else:\n",
    "        return row['age']\n",
    "\n",
    "# apply the function to each row of the dataframe and fill the missing age values with the corresponding mean age\n",
    "Test['age'] = Test.apply(fill_age, axis=1)\n",
    "\n",
    "#for all binary columns we will apply mode imputation for missing values\n",
    "#first we will create a list of all binary columns\n",
    "binary_colsTest = ['elective_surgery', 'apache_post_operative', 'gcs_unable_apache', 'intubated_apache', 'ventilated_apache','immunosuppression', 'solid_tumor_with_metastasis']\n",
    "\n",
    "binary_colsTrain = ['elective_surgery', 'apache_post_operative', 'gcs_unable_apache', 'intubated_apache', 'ventilated_apache','immunosuppression', 'solid_tumor_with_metastasis','hospital_death']\n",
    "#now we will apply mode imputation on these columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "binary_colsTest = [col for col in Train.columns if Train[col].dtype == 'object' or col in binary_colsTest]\n",
    "binary_colsTrain = [col for col in Test.columns if Test[col].dtype == 'object' or col in binary_colsTrain]\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "Train[binary_colsTrain] = imputer.fit_transform(Train[binary_colsTrain])\n",
    "Test[binary_colsTest] = imputer.fit_transform(Test[binary_colsTest])\n",
    "\n",
    "numeric_cols = [col for col in Train.select_dtypes(include=[np.number]).columns if col not in binary_colsTrain]\n",
    "numeric_colsTest = [col for col in Test.select_dtypes(include=[np.number]).columns if col not in binary_colsTrain]\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# create an instance of KNNImputer with k=3\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# fill missing values in Train dataframe\n",
    "Train[numeric_cols] = imputer.fit_transform(Train[numeric_cols])\n",
    "\n",
    "# fill missing values in Test dataframe\n",
    "Test[numeric_colsTest] = imputer.fit_transform(Test[numeric_colsTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehot = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehot = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehot = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehot = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehot = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehot = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehot = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehotTest = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehotTest = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehotTest = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehotTest = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehotTest = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehotTest = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\300161806.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  df_onehotTest = pd.get_dummies(Test)\n"
     ]
    }
   ],
   "source": [
    "df_onehot = pd.get_dummies(Train)\n",
    "df_onehotTest = pd.get_dummies(Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_onehot.dtypes\n",
    "X = df_onehot.loc[:, df_onehot.columns != 'hospital_death']\n",
    "y = df_onehot['hospital_death']\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.23.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (3.6.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24.2->mlxtend) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pip install mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.0min\n",
      "\n",
      "[2023-09-29 15:03:36] Features: 1/50 -- score: 0.7280930987959879[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   29.8s\n",
      "\n",
      "[2023-09-29 15:06:47] Features: 2/50 -- score: 0.7339247721042315[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   27.8s\n",
      "\n",
      "[2023-09-29 15:08:15] Features: 3/50 -- score: 0.7400655058809711[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   34.3s\n",
      "\n",
      "[2023-09-29 15:09:58] Features: 4/50 -- score: 0.7420315177052601[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   40.6s\n",
      "\n",
      "[2023-09-29 15:11:59] Features: 5/50 -- score: 0.7428971687431102[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   48.9s\n",
      "\n",
      "[2023-09-29 15:14:39] Features: 6/50 -- score: 0.7433322213527035[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.0min\n",
      "\n",
      "[2023-09-29 15:17:28] Features: 7/50 -- score: 0.7439338813561885[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.0min\n",
      "\n",
      "[2023-09-29 15:20:43] Features: 8/50 -- score: 0.7445867673584436[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.2min\n",
      "\n",
      "[2023-09-29 15:24:15] Features: 9/50 -- score: 0.7445952613090515[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.3min\n",
      "\n",
      "[2023-09-29 15:28:11] Features: 10/50 -- score: 0.7445717442051626[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.4min\n",
      "\n",
      "[2023-09-29 15:31:57] Features: 11/50 -- score: 0.7445114343557018[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.5min\n",
      "\n",
      "[2023-09-29 15:36:08] Features: 12/50 -- score: 0.7444105638351212[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.7min\n",
      "\n",
      "[2023-09-29 15:40:35] Features: 13/50 -- score: 0.7443648059248742[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.4min\n",
      "\n",
      "[2023-09-29 15:44:28] Features: 14/50 -- score: 0.7444567816928042[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.5min\n",
      "\n",
      "[2023-09-29 15:48:42] Features: 15/50 -- score: 0.7442133907818859[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.3min\n",
      "\n",
      "[2023-09-29 15:54:05] Features: 16/50 -- score: 0.7437283082520154[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.4min\n",
      "\n",
      "[2023-09-29 15:59:30] Features: 17/50 -- score: 0.7433880809040196[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.5min\n",
      "\n",
      "[2023-09-29 16:04:48] Features: 18/50 -- score: 0.7431365865518744[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.5min\n",
      "\n",
      "[2023-09-29 16:10:10] Features: 19/50 -- score: 0.7428077015575035[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.5min\n",
      "\n",
      "[2023-09-29 16:15:18] Features: 20/50 -- score: 0.7424481721565825[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.5min\n",
      "\n",
      "[2023-09-29 16:20:27] Features: 21/50 -- score: 0.741725933074724[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.7min\n",
      "\n",
      "[2023-09-29 16:25:47] Features: 22/50 -- score: 0.7414599752134609[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.6min\n",
      "\n",
      "[2023-09-29 16:30:58] Features: 23/50 -- score: 0.7421941688238771[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.6min\n",
      "\n",
      "[2023-09-29 16:36:09] Features: 24/50 -- score: 0.743785276228689[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.5min\n",
      "\n",
      "[2023-09-29 16:41:19] Features: 25/50 -- score: 0.7440441140545275[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.6min\n",
      "\n",
      "[2023-09-29 16:46:18] Features: 26/50 -- score: 0.7445501412705974[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.6min\n",
      "\n",
      "[2023-09-29 16:51:16] Features: 27/50 -- score: 0.7449090615588363[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.6min\n",
      "\n",
      "[2023-09-29 16:56:11] Features: 28/50 -- score: 0.7448872337564614[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.7min\n",
      "\n",
      "[2023-09-29 17:00:53] Features: 29/50 -- score: 0.7440968644419282[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.4min\n",
      "\n",
      "[2023-09-29 17:05:18] Features: 30/50 -- score: 0.7428299710268333[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.4min\n",
      "\n",
      "[2023-09-29 17:09:41] Features: 31/50 -- score: 0.7416646547301287[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.4min\n",
      "\n",
      "[2023-09-29 17:14:03] Features: 32/50 -- score: 0.7403602062063073[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.4min\n",
      "\n",
      "[2023-09-29 17:18:22] Features: 33/50 -- score: 0.7400289222709769[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  3.1min\n",
      "\n",
      "[2023-09-29 17:24:19] Features: 34/50 -- score: 0.7386054378539849[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.0min\n",
      "\n",
      "[2023-09-29 17:31:03] Features: 35/50 -- score: 0.7380185900143457[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  3.9min\n",
      "\n",
      "[2023-09-29 17:37:37] Features: 36/50 -- score: 0.7372814841790445[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.2min\n",
      "\n",
      "[2023-09-29 17:44:33] Features: 37/50 -- score: 0.7360922112899728[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.3min\n",
      "\n",
      "[2023-09-29 17:51:21] Features: 38/50 -- score: 0.7350384295606613[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.5min\n",
      "\n",
      "[2023-09-29 17:59:03] Features: 39/50 -- score: 0.7345091248376485[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.4min\n",
      "\n",
      "[2023-09-29 18:05:55] Features: 40/50 -- score: 0.7334637047629073[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.4min\n",
      "\n",
      "[2023-09-29 18:12:37] Features: 41/50 -- score: 0.73237028352322[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.4min\n",
      "\n",
      "[2023-09-29 18:19:18] Features: 42/50 -- score: 0.7323598850629944[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.5min\n",
      "\n",
      "[2023-09-29 18:26:07] Features: 43/50 -- score: 0.7315842508771147[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.5min\n",
      "\n",
      "[2023-09-29 18:32:35] Features: 44/50 -- score: 0.7348009481155201[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.2min\n",
      "\n",
      "[2023-09-29 18:38:43] Features: 45/50 -- score: 0.7352114425648597[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.2min\n",
      "\n",
      "[2023-09-29 18:44:43] Features: 46/50 -- score: 0.7372486643553794[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.3min\n",
      "\n",
      "[2023-09-29 18:50:49] Features: 47/50 -- score: 0.7361388786517479[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  4.3min\n",
      "\n",
      "[2023-09-29 18:56:43] Features: 48/50 -- score: 0.7344275629645138[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  3.2min\n",
      "\n",
      "[2023-09-29 19:00:55] Features: 49/50 -- score: 0.7331380408005252[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  3.0min\n",
      "\n",
      "[2023-09-29 19:04:55] Features: 50/50 -- score: 0.7322775889014357"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "fwd_feature_selector = SFS(KNeighborsClassifier(), k_features=(20,50), forward=True,\n",
    "                                                  floating=False, verbose=2, scoring='roc_auc', cv=5).fit(trainX, trainy)\n",
    "#cv is croos validation 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gcs_motor_apache',\n",
       " 'd1_spo2_min',\n",
       " 'apache_4a_icu_death_prob',\n",
       " 'ethnicity_Asian',\n",
       " 'ethnicity_Hispanic',\n",
       " 'ethnicity_Native American',\n",
       " 'icu_admit_source_Operating Room / Recovery',\n",
       " 'icu_admit_source_Other ICU',\n",
       " 'icu_stay_type_readmit',\n",
       " 'icu_type_Med-Surg ICU',\n",
       " 'apache_3j_bodysystem_Gastrointestinal',\n",
       " 'apache_3j_bodysystem_Genitourinary',\n",
       " 'apache_3j_bodysystem_Gynecological',\n",
       " 'apache_3j_bodysystem_Hematological',\n",
       " 'apache_3j_bodysystem_Metabolic',\n",
       " 'apache_3j_bodysystem_Musculoskeletal/Skin',\n",
       " 'apache_2_bodysystem_Gastrointestinal',\n",
       " 'apache_2_bodysystem_Haematologic',\n",
       " 'apache_2_bodysystem_Metabolic',\n",
       " 'apache_2_bodysystem_Renal/Genitourinary',\n",
       " 'apache_2_bodysystem_Undefined Diagnoses',\n",
       " 'apache_2_bodysystem_Undefined diagnoses',\n",
       " 'apache_post_operative_0',\n",
       " 'gcs_unable_apache_0.0',\n",
       " 'gcs_unable_apache_1.0',\n",
       " 'intubated_apache_0',\n",
       " 'intubated_apache_1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fwd_feature_selector.k_feature_names_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266363526335636\n",
      "0.8147773258042729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Transform X_test to contain only the selected features\n",
    "X_test_transformed = fwd_feature_selector.transform(trainX)\n",
    "\n",
    "# Fit the model on the transformed X_train\n",
    "selected_features = fwd_feature_selector.k_feature_names_\n",
    "pipe_kn = Pipeline([(\"scaler\", MinMaxScaler()), (\"knr\", KNeighborsClassifier(n_neighbors=350))])\n",
    "pipe_kn.fit(X_test_transformed, trainy)\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=350)\n",
    "kn.fit(X_test_transformed, trainy)\n",
    "\n",
    "\n",
    "Testtransofrm = fwd_feature_selector.transform(testX)\n",
    "\n",
    "# Predict and evaluate on the transformed X_test\n",
    "y_pred = pipe_kn.predict_proba(Testtransofrm)[:, 1]\n",
    "y_pred2= kn.predict_proba(Testtransofrm)[:, 1]\n",
    "print(roc_auc_score(testy, y_pred))\n",
    "print(roc_auc_score(testy, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the original Test set\n",
    "TT = fwd_feature_selector.transform(df_onehotTest)\n",
    "\n",
    "hospital_death_prob = pipe_kn.predict_proba(TT)\n",
    "# The predicted probabilities of each class are stored in the second column of the output array\n",
    "hospital_death = hospital_death_prob[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8543857220300923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTre\n",
    "# Transform X_test to contain only the selected features\n",
    "X_test_transformed = fwd_feature_selector.transform(trainX)\n",
    "\n",
    "\n",
    "\n",
    "DT = DecisionTre(max_depth=7, min_samples_leaf=100)\n",
    "DT.fit(X_test_transformed, trainy)\n",
    "\n",
    "\n",
    "Testtransofrm = fwd_feature_selector.transform(testX)\n",
    "\n",
    "# Predict and evaluate on the transformed X_test\n",
    "y_pred = DT.predict_proba(Testtransofrm)[:, 1]\n",
    "# y_pred2= kn.predict_proba(Testtransofrm)[:, 1]\n",
    "print(roc_auc_score(testy, y_pred))\n",
    "# print(roc_auc_score(testy, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the original Test set\n",
    "TT = fwd_feature_selector.transform(df_onehotTest)\n",
    "\n",
    "hospital_death_prob = DT.predict_proba(TT)\n",
    "# The predicted probabilities of each class are stored in the second column of the output array\n",
    "hospital_death = hospital_death_prob[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsFWDSLEECTION.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv(\"Data/train.csv\")\n",
    "tesst = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\2759698474.py:1: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  t.fillna(t.median(), inplace=True)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_12744\\2759698474.py:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  tesst.fillna(tesst.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "t.fillna(t.median(), inplace=True)\n",
    "tesst.fillna(tesst.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing categorical data with mode\n",
    "t.fillna(t.mode().iloc[0], inplace=True)\n",
    "tesst.fillna(tesst.mode().iloc[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehotDROP = pd.get_dummies(t)\n",
    "df_onehotTesDROPt = pd.get_dummies(tesst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_onehot.dtypes\n",
    "X = df_onehotDROP.loc[:, df_onehotDROP.columns != 'hospital_death']\n",
    "y = df_onehot['hospital_death']\n",
    "trainXd, testXd, trainyd, testyd = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00217343, 0.00521543, 0.01272274, 0.0101887 , 0.        ,\n",
       "       0.00798081, 0.00439809, 0.00935693, 0.        , 0.00192746,\n",
       "       0.00272905, 0.        , 0.00311058, 0.00526231, 0.        ,\n",
       "       0.00237686, 0.00137556, 0.00696748, 0.02692817, 0.00998157,\n",
       "       0.00388648, 0.01456072, 0.0048124 , 0.01519623, 0.06254202,\n",
       "       0.00819348, 0.00801359, 0.0149001 , 0.00277153, 0.00150445,\n",
       "       0.00059585, 0.        , 0.00174114, 0.00238369, 0.00206435,\n",
       "       0.00336535, 0.00454487, 0.00830724, 0.00670679, 0.        ,\n",
       "       0.00126606, 0.00264267, 0.        , 0.00051073, 0.01530417,\n",
       "       0.01502238, 0.1793666 , 0.50310175, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00216931,\n",
       "       0.00183089, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=7)  \n",
    "model.fit(trainXd,trainyd)\n",
    "model.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apache_4a_icu_death_prob                   0.503102\n",
       "apache_4a_hospital_death_prob              0.179367\n",
       "d1_spo2_min                                0.062542\n",
       "d1_diasbp_min                              0.026928\n",
       "d1_glucose_max                             0.015304\n",
       "                                             ...   \n",
       "icu_admit_source_Other Hospital            0.000000\n",
       "icu_admit_source_Other ICU                 0.000000\n",
       "icu_stay_type_admit                        0.000000\n",
       "icu_stay_type_transfer                     0.000000\n",
       "apache_2_bodysystem_Undefined diagnoses    0.000000\n",
       "Length: 95, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(model.feature_importances_,index=trainXd.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract column names whose importance is less than 0.01 # 0.002\n",
    "col_to_drop = feature_imp[feature_imp < 0.01].index\n",
    "#remove these columns from the training and test sets\n",
    "trainXDROP = trainXd.drop(col_to_drop, axis=1)\n",
    "testXDROP = testXd.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehotTesDROPtD=df_onehotTesDROPt.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 11)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehotTesDROPtD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 11)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testXDROP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854342419520066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTre\n",
    "# Transform X_test to contain only the selected features\n",
    "DT = DecisionTre(max_depth=7, min_samples_leaf=50)\n",
    "DT.fit(trainXDROP, trainyd)\n",
    "\n",
    "# Predict and evaluate on the transformed X_test\n",
    "y_pred = DT.predict_proba(testXDROP)[:, 1]\n",
    "# y_pred2= kn.predict_proba(Testtransofrm)[:, 1]\n",
    "print(roc_auc_score(testyd, y_pred))\n",
    "# print(roc_auc_score(testy, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_death_prob = DT.predict_proba(df_onehotTesDROPtD)\n",
    "# The predicted probabilities of each class are stored in the second column of the output array\n",
    "hospital_death = hospital_death_prob[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsfeatureimp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
