{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "Train = pd.read_csv(\"Data/train.csv\")\n",
    "Test = pd.read_csv(\"Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.drop('gender', axis=1, inplace=True)\n",
    "Test.drop('gender', axis=1, inplace=True)\n",
    "Train.drop('apache_3j_bodysystem', axis=1, inplace=True)\n",
    "Test.drop('apache_3j_bodysystem', axis=1, inplace=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#normalise Train['pre_icu_los_days']\n",
    "Train['pre_icu_los_days'] = np.log1p(Train['pre_icu_los_days'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "\n",
    "#normalise Train['pre_icu_los_days']\n",
    "Test['pre_icu_los_days'] = np.log1p(Test['pre_icu_los_days'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#simialrly normalise apache_2_diagnosis\n",
    "Train['apache_2_diagnosis'] = np.log1p(Train['apache_2_diagnosis'])\n",
    "Test['apache_2_diagnosis'] = np.log1p(Test['apache_2_diagnosis'])\n",
    "#do for apache_3j_diagnosis as well for both train and test\n",
    "Train['apache_3j_diagnosis'] = np.log1p(Train['apache_3j_diagnosis'])\n",
    "#do for test as well\n",
    "Test['apache_3j_diagnosis'] = np.log1p(Test['apache_3j_diagnosis'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for resprate_apache as well\n",
    "Train['d1_resprate_max'] = np.log1p(Train['d1_resprate_max'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for test as well\n",
    "Test['d1_resprate_max'] = np.log1p(Test['d1_resprate_max'])\n",
    "#make hsitogram of normlaised Train['pre_icu_los_days']\n",
    "#do for temp_apache as well\n",
    "Train['temp_apache'] = np.log1p(Train['temp_apache'])\n",
    "#do for test as well\n",
    "Test['temp_apache'] = np.log1p(Test['temp_apache'])\n",
    "#do foor d1_resprate_max as well\n",
    "Train['d1_resprate_max'] = np.log1p(Train['d1_resprate_max'])\n",
    "#do for test as well\n",
    "Test['d1_resprate_max'] = np.log1p(Test['d1_resprate_max'])\n",
    "#do for d1_temp_min\n",
    "Train['d1_temp_min'] = np.log1p(Train['d1_temp_min'])\n",
    "#do for test as well\n",
    "Test['d1_temp_min'] = np.log1p(Test['d1_temp_min'])\n",
    "#do foe h1_spo2_max\n",
    "Train['h1_spo2_max'] = np.log1p(Train['h1_spo2_max'])\n",
    "#do for test as well\n",
    "Test['h1_spo2_max'] = np.log1p(Test['h1_spo2_max'])\n",
    "#do for h1_spo2_min\n",
    "Train['h1_spo2_min'] = np.log1p(Train['h1_spo2_min'])\n",
    "#do for test as well\n",
    "Test['h1_spo2_min'] = np.log1p(Test['h1_spo2_min'])\n",
    "#do for d1_glucose_max\n",
    "Train['d1_glucose_max'] = np.log1p(Train['d1_glucose_max'])\n",
    "#do for test as well\n",
    "Test['d1_glucose_max'] = np.log1p(Test['d1_glucose_max'])\n",
    "#since all these r heavily skewed andaffected by the outliers we will fill them using median imputation\n",
    "\n",
    "# fill null values with median for temp_apache\n",
    "Train['temp_apache'].fillna(Train['temp_apache'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for d1_potassium_max\n",
    "Train['d1_potassium_max'].fillna(Train['d1_potassium_max'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_hospital_death_prob\n",
    "Train['apache_4a_hospital_death_prob'].fillna(Train['apache_4a_hospital_death_prob'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_icu_death_prob\n",
    "Train['apache_4a_icu_death_prob'].fillna(Train['apache_4a_icu_death_prob'].median(), inplace=True)\n",
    "#since all these r heavily skewed andaffected by the outliers we will fill them using median imputation\n",
    "\n",
    "Test['temp_apache'].fillna(Test['temp_apache'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for d1_potassium_max\n",
    "Test['d1_potassium_max'].fillna(Test['d1_potassium_max'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_hospital_death_prob\n",
    "Test['apache_4a_hospital_death_prob'].fillna(Test['apache_4a_hospital_death_prob'].median(), inplace=True)\n",
    "\n",
    "# fill null values with median for apache_4a_icu_death_prob\n",
    "Test['apache_4a_icu_death_prob'].fillna(Test['apache_4a_icu_death_prob'].median(), inplace=True)\n",
    "\n",
    "# group the dataframe by apache_2_bodysystem and calculate the mean age for each group\n",
    "mean_age_by_bodysystem = Train.groupby('apache_2_bodysystem')['age'].mean()\n",
    "\n",
    "# define a function that takes a row of the dataframe as input and returns the mean age of the corresponding apache_2_bodysystem\n",
    "def fill_age(row):\n",
    "    if pd.isnull(row['age']):\n",
    "        if pd.isnull(row['apache_2_bodysystem']):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return mean_age_by_bodysystem[row['apache_2_bodysystem']]\n",
    "    else:\n",
    "        return row['age']\n",
    "\n",
    "# apply the function to each row of the dataframe and fill the missing age values with the corresponding mean age\n",
    "Train['age'] = Train.apply(fill_age, axis=1)\n",
    "\n",
    "# group the dataframe by apache_2_bodysystem and calculate the mean age for each group\n",
    "mean_age_by_bodysystem = Test.groupby('apache_2_bodysystem')['age'].mean()\n",
    "\n",
    "# define a function that takes a row of the dataframe as input and returns the mean age of the corresponding apache_2_bodysystem\n",
    "def fill_age(row):\n",
    "    if pd.isnull(row['age']):\n",
    "        if pd.isnull(row['apache_2_bodysystem']):\n",
    "            return np.nan\n",
    "        else:\n",
    "            return mean_age_by_bodysystem[row['apache_2_bodysystem']]\n",
    "    else:\n",
    "        return row['age']\n",
    "\n",
    "# apply the function to each row of the dataframe and fill the missing age values with the corresponding mean age\n",
    "Test['age'] = Test.apply(fill_age, axis=1)\n",
    "\n",
    "#for all binary columns we will apply mode imputation for missing values\n",
    "#first we will create a list of all binary columns\n",
    "binary_colsTest = ['elective_surgery', 'apache_post_operative', 'gcs_unable_apache', 'intubated_apache', 'ventilated_apache','immunosuppression', 'solid_tumor_with_metastasis']\n",
    "\n",
    "binary_colsTrain = ['elective_surgery', 'apache_post_operative', 'gcs_unable_apache', 'intubated_apache', 'ventilated_apache','immunosuppression', 'solid_tumor_with_metastasis','hospital_death']\n",
    "#now we will apply mode imputation on these columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "binary_colsTest = [col for col in Train.columns if Train[col].dtype == 'object' or col in binary_colsTest]\n",
    "binary_colsTrain = [col for col in Test.columns if Test[col].dtype == 'object' or col in binary_colsTrain]\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "Train[binary_colsTrain] = imputer.fit_transform(Train[binary_colsTrain])\n",
    "Test[binary_colsTest] = imputer.fit_transform(Test[binary_colsTest])\n",
    "\n",
    "numeric_cols = [col for col in Train.select_dtypes(include=[np.number]).columns if col not in binary_colsTrain]\n",
    "numeric_colsTest = [col for col in Test.select_dtypes(include=[np.number]).columns if col not in binary_colsTrain]\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# create an instance of KNNImputer with k=5\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# fill missing values in Train dataframe\n",
    "Train[numeric_cols] = imputer.fit_transform(Train[numeric_cols])\n",
    "\n",
    "# fill missing values in Test dataframe\n",
    "Test[numeric_colsTest] = imputer.fit_transform(Test[numeric_colsTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ethnicity',\n",
       " 'icu_admit_source',\n",
       " 'icu_stay_type',\n",
       " 'icu_type',\n",
       " 'apache_2_bodysystem',\n",
       " 'elective_surgery',\n",
       " 'apache_post_operative',\n",
       " 'gcs_unable_apache',\n",
       " 'intubated_apache',\n",
       " 'ventilated_apache',\n",
       " 'immunosuppression',\n",
       " 'solid_tumor_with_metastasis']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewTest=Test.copy()\n",
    "NewTrain=Train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 90)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NewTest[numeric_colsTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "    NewTrain[col] = pd.cut(NewTrain[col], bins=5, labels=[1,2,3,4,5],include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Categorical.min() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hamza\\Documents\\7th Sem\\IDM\\Challenge 1\\OnehotFWDDT.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/OnehotFWDDT.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m numeric_cols:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hamza/Documents/7th%20Sem/IDM/Challenge%201/OnehotFWDDT.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     NewTest[col] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mcut(NewTest[col], bins\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, labels\u001b[39m=\u001b[39;49m[\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m5\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\reshape\\tile.py:258\u001b[0m, in \u001b[0;36mcut\u001b[1;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mif\u001b[39;00m sz \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    256\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot cut empty array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 258\u001b[0m rng \u001b[39m=\u001b[39m (nanops\u001b[39m.\u001b[39;49mnanmin(x), nanops\u001b[39m.\u001b[39mnanmax(x))\n\u001b[0;32m    259\u001b[0m mn, mx \u001b[39m=\u001b[39m (mi \u001b[39m+\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mfor\u001b[39;00m mi \u001b[39min\u001b[39;00m rng)\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misinf(mn) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39misinf(mx):\n\u001b[0;32m    262\u001b[0m     \u001b[39m# GH 24314\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m--> 418\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, mask\u001b[39m=\u001b[39mmask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    420\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[0;32m    421\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\nanops.py:1051\u001b[0m, in \u001b[0;36m_nanminmax.<locals>.reduction\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m   1050\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1051\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(values, meth)(axis)\n\u001b[0;32m   1053\u001b[0m result \u001b[39m=\u001b[39m _maybe_null_out(result, axis, mask, values\u001b[39m.\u001b[39mshape)\n\u001b[0;32m   1054\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Categorical.min() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for col in numeric_cols:\n",
    "    NewTest[col] = pd.cut(NewTest[col], bins=5, labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.23.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (3.6.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24.2->mlxtend) (2022.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hamza\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pip install mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Train = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Train = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Train = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Train = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Train = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Train = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:2: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Train = pd.get_dummies(Train)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Test = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Test = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Test = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Test = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Test = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Test = pd.get_dummies(Test)\n",
      "C:\\Users\\hamza\\AppData\\Local\\Temp\\ipykernel_11628\\1147109646.py:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  Test = pd.get_dummies(Test)\n"
     ]
    }
   ],
   "source": [
    "#one hot encode\n",
    "Train = pd.get_dummies(Train)\n",
    "Test = pd.get_dummies(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define x as all columns except target\n",
    "X=Train.loc[:,Train.columns!='hospital_death']\n",
    "y=Train['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now run categoricalNB on categorical_cols \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and test sets with a test size of 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    5.1s\n",
      "\n",
      "[2023-09-27 21:29:04] Features: 1/40 -- score: 0.8339604615025304[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    9.0s\n",
      "\n",
      "[2023-09-27 21:29:24] Features: 2/40 -- score: 0.8335646343576357[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    9.0s\n",
      "\n",
      "[2023-09-27 21:29:43] Features: 3/40 -- score: 0.8326268865352136[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    7.8s\n",
      "\n",
      "[2023-09-27 21:30:03] Features: 4/40 -- score: 0.831780424088354[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   11.3s\n",
      "\n",
      "[2023-09-27 21:30:27] Features: 5/40 -- score: 0.8314391782203744[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   11.5s\n",
      "\n",
      "[2023-09-27 21:30:51] Features: 6/40 -- score: 0.832613952678015[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    9.6s\n",
      "\n",
      "[2023-09-27 21:31:10] Features: 7/40 -- score: 0.8329923694692253[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    9.6s\n",
      "\n",
      "[2023-09-27 21:31:31] Features: 8/40 -- score: 0.8349554116828827[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    9.7s\n",
      "\n",
      "[2023-09-27 21:31:51] Features: 9/40 -- score: 0.8358393621705072[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   11.6s\n",
      "\n",
      "[2023-09-27 21:32:15] Features: 10/40 -- score: 0.8379429251319486[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   13.1s\n",
      "\n",
      "[2023-09-27 21:32:41] Features: 11/40 -- score: 0.8411953567267174[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   13.3s\n",
      "\n",
      "[2023-09-27 21:33:06] Features: 12/40 -- score: 0.8431855678026787[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   13.0s\n",
      "\n",
      "[2023-09-27 21:33:30] Features: 13/40 -- score: 0.8458377537886683[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   13.4s\n",
      "\n",
      "[2023-09-27 21:33:55] Features: 14/40 -- score: 0.8477087620490842[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   14.4s\n",
      "\n",
      "[2023-09-27 21:34:28] Features: 15/40 -- score: 0.8492793837044139[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   15.9s\n",
      "\n",
      "[2023-09-27 21:34:59] Features: 16/40 -- score: 0.8499882643185481[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   16.5s\n",
      "\n",
      "[2023-09-27 21:35:29] Features: 17/40 -- score: 0.8503563834383252[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   17.7s\n",
      "\n",
      "[2023-09-27 21:35:58] Features: 18/40 -- score: 0.8509425316528907[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   18.8s\n",
      "\n",
      "[2023-09-27 21:36:31] Features: 19/40 -- score: 0.8510479618156213[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   17.5s\n",
      "\n",
      "[2023-09-27 21:37:01] Features: 20/40 -- score: 0.8510360834784766[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   16.2s\n",
      "\n",
      "[2023-09-27 21:37:29] Features: 21/40 -- score: 0.8510211942157987[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   15.2s\n",
      "\n",
      "[2023-09-27 21:37:55] Features: 22/40 -- score: 0.8509248199019049[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   16.8s\n",
      "\n",
      "[2023-09-27 21:38:26] Features: 23/40 -- score: 0.8513452605349426[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   17.1s\n",
      "\n",
      "[2023-09-27 21:38:54] Features: 24/40 -- score: 0.8516190684542331[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   17.1s\n",
      "\n",
      "[2023-09-27 21:39:21] Features: 25/40 -- score: 0.8516587727392784[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   17.3s\n",
      "\n",
      "[2023-09-27 21:39:49] Features: 26/40 -- score: 0.8517021114900233[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   17.9s\n",
      "\n",
      "[2023-09-27 21:40:17] Features: 27/40 -- score: 0.8532016690089549[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   18.1s\n",
      "\n",
      "[2023-09-27 21:40:46] Features: 28/40 -- score: 0.85343588003293[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   17.8s\n",
      "\n",
      "[2023-09-27 21:41:13] Features: 29/40 -- score: 0.8538033799022509[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   18.0s\n",
      "\n",
      "[2023-09-27 21:41:40] Features: 30/40 -- score: 0.8540640393411429[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   19.0s\n",
      "\n",
      "[2023-09-27 21:42:08] Features: 31/40 -- score: 0.8540567699813815[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   18.7s\n",
      "\n",
      "[2023-09-27 21:42:36] Features: 32/40 -- score: 0.8540402428216171[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   19.4s\n",
      "\n",
      "[2023-09-27 21:43:04] Features: 33/40 -- score: 0.8539923569343044[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   20.5s\n",
      "\n",
      "[2023-09-27 21:43:32] Features: 34/40 -- score: 0.8539411626879765[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   20.4s\n",
      "\n",
      "[2023-09-27 21:44:00] Features: 35/40 -- score: 0.8538927490777783[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   21.0s\n",
      "\n",
      "[2023-09-27 21:44:29] Features: 36/40 -- score: 0.8538196475392491[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   21.8s\n",
      "\n",
      "[2023-09-27 21:44:58] Features: 37/40 -- score: 0.8536987073636249[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   22.3s\n",
      "\n",
      "[2023-09-27 21:45:27] Features: 38/40 -- score: 0.8535463923410969[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   22.8s\n",
      "\n",
      "[2023-09-27 21:45:56] Features: 39/40 -- score: 0.8534490975929799[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   23.1s\n",
      "\n",
      "[2023-09-27 21:46:25] Features: 40/40 -- score: 0.8532796742852924"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "fwd_feature_selectorNB = SFS(GaussianNB(), k_features=(10,40), forward=True,\n",
    "                                                  floating=False, verbose=2, scoring='roc_auc', cv=5).fit(X_train, y_train)\n",
    "#cv is croos validation 5 times\n",
    "#The cv=5 parameter means that this process is done using 5-fold cross-validation on your training data (X_train and y_train). \n",
    "# In each fold of the cross-validation, 4/5 of the data is used for training and 1/5 is used for validation.\n",
    "# The ROC AUC score is averaged over the 5 folds to give a more robust estimate of the model’s performance.\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-06}\n",
      "0.8571660105503828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(GaussianNB(), param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the GridSearchCV object on the transformed X_train\n",
    "grid_search.fit(fwd_feature_selectorNB.transform(X_train), y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding ROC AUC score\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8489227228462012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Transform X_test to contain only the selected features\n",
    "X_test_transformed = fwd_feature_selectorNB.transform(X_test)\n",
    "\n",
    "# Fit the model on the transformed X_train\n",
    "model = GaussianNB(var_smoothing=1e-06)\n",
    "model.fit(fwd_feature_selectorNB.transform(X_train), y_train)\n",
    "\n",
    "# Predict and evaluate on the transformed X_test\n",
    "y_pred = model.predict_proba(X_test_transformed)[:, 1]\n",
    "print(roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   15.4s\n",
      "\n",
      "[2023-09-27 20:37:07] Features: 1/40 -- score: 0.842153404087407[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   26.3s\n",
      "\n",
      "[2023-09-27 20:37:48] Features: 2/40 -- score: 0.8448594904507873[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   33.7s\n",
      "\n",
      "[2023-09-27 20:38:38] Features: 3/40 -- score: 0.8448594904507873[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   27.0s\n",
      "\n",
      "[2023-09-27 20:39:17] Features: 4/40 -- score: 0.8442939919512469[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   26.7s\n",
      "\n",
      "[2023-09-27 20:39:58] Features: 5/40 -- score: 0.8437171555398612[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   38.2s\n",
      "\n",
      "[2023-09-27 20:40:50] Features: 6/40 -- score: 0.8426379346516104[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   29.2s\n",
      "\n",
      "[2023-09-27 20:41:33] Features: 7/40 -- score: 0.8411997152353013[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   27.4s\n",
      "\n",
      "[2023-09-27 20:42:14] Features: 8/40 -- score: 0.8381822886013062[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   28.5s\n",
      "\n",
      "[2023-09-27 20:42:58] Features: 9/40 -- score: 0.8381822886013062[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   30.1s\n",
      "\n",
      "[2023-09-27 20:43:42] Features: 10/40 -- score: 0.8360857911600352[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   30.8s\n",
      "\n",
      "[2023-09-27 20:44:28] Features: 11/40 -- score: 0.8334830555928097[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   32.5s\n",
      "\n",
      "[2023-09-27 20:45:19] Features: 12/40 -- score: 0.8312455793078797[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   34.6s\n",
      "\n",
      "[2023-09-27 20:46:10] Features: 13/40 -- score: 0.826248070422127[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   36.8s\n",
      "\n",
      "[2023-09-27 20:47:09] Features: 14/40 -- score: 0.8203550765700143[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   41.2s\n",
      "\n",
      "[2023-09-27 20:48:11] Features: 15/40 -- score: 0.8139883184082933[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   42.5s\n",
      "\n",
      "[2023-09-27 20:49:15] Features: 16/40 -- score: 0.8075021565834121[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   45.3s\n",
      "\n",
      "[2023-09-27 20:50:23] Features: 17/40 -- score: 0.8074500003209216[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   42.9s\n",
      "\n",
      "[2023-09-27 20:51:27] Features: 18/40 -- score: 0.7992669252670043[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   45.1s\n",
      "\n",
      "[2023-09-27 20:52:34] Features: 19/40 -- score: 0.7879326204433065[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   48.1s\n",
      "\n",
      "[2023-09-27 20:53:44] Features: 20/40 -- score: 0.7799182673339755[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   46.1s\n",
      "\n",
      "[2023-09-27 20:54:52] Features: 21/40 -- score: 0.7705318346162393[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   48.0s\n",
      "\n",
      "[2023-09-27 20:56:02] Features: 22/40 -- score: 0.7592563172552712[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   49.9s\n",
      "\n",
      "[2023-09-27 20:57:15] Features: 23/40 -- score: 0.7594366941053721[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   51.0s\n",
      "\n",
      "[2023-09-27 20:58:29] Features: 24/40 -- score: 0.7571709811228027[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   52.9s\n",
      "\n",
      "[2023-09-27 20:59:45] Features: 25/40 -- score: 0.7571504078886837[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   54.5s\n",
      "\n",
      "[2023-09-27 21:01:02] Features: 26/40 -- score: 0.7550823885267065[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   55.9s\n",
      "\n",
      "[2023-09-27 21:02:21] Features: 27/40 -- score: 0.7485060765292486[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   57.9s\n",
      "\n",
      "[2023-09-27 21:03:42] Features: 28/40 -- score: 0.7469775821685511[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   59.2s\n",
      "\n",
      "[2023-09-27 21:05:04] Features: 29/40 -- score: 0.7415436119313781[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.0min\n",
      "\n",
      "[2023-09-27 21:06:29] Features: 30/40 -- score: 0.741466651824714[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.0min\n",
      "\n",
      "[2023-09-27 21:07:54] Features: 31/40 -- score: 0.7344999582096137[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.1min\n",
      "\n",
      "[2023-09-27 21:09:25] Features: 32/40 -- score: 0.7258758675171604[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.1min\n",
      "\n",
      "[2023-09-27 21:10:54] Features: 33/40 -- score: 0.716456358331453[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.1min\n",
      "\n",
      "[2023-09-27 21:12:24] Features: 34/40 -- score: 0.7081568630789775[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.2min\n",
      "\n",
      "[2023-09-27 21:13:56] Features: 35/40 -- score: 0.6994909623579925[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.2min\n",
      "\n",
      "[2023-09-27 21:15:30] Features: 36/40 -- score: 0.6891572092959034[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.3min\n",
      "\n",
      "[2023-09-27 21:17:05] Features: 37/40 -- score: 0.6860809267870251[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.3min\n",
      "\n",
      "[2023-09-27 21:18:41] Features: 38/40 -- score: 0.6792215735571371[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.3min\n",
      "\n",
      "[2023-09-27 21:20:17] Features: 39/40 -- score: 0.6743734838628974[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.4min\n",
      "\n",
      "[2023-09-27 21:21:55] Features: 40/40 -- score: 0.666876381998523"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "fwd_feature_selector = SFS(DecisionTreeClassifier(), k_features=(20,50), forward=True,\n",
    "                                                  floating=False, verbose=2, scoring='roc_auc', cv=5).fit(X_train, y_train)\n",
    "#cv is croos validation 5 times\n",
    "#The cv=5 parameter means that this process is done using 5-fold cross-validation on your training data (X_train and y_train). \n",
    "# In each fold of the cross-validation, 4/5 of the data is used for training and 1/5 is used for validation.\n",
    "# The ROC AUC score is averaged over the 5 folds to give a more robust estimate of the model’s performance.\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495033136118859\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Transform X_test to contain only the selected features\n",
    "X_test_transformed = fwd_feature_selector.transform(X_test)\n",
    "\n",
    "# Fit the model on the transformed X_train\n",
    "model = DecisionTreeClassifier(max_depth=5,min_samples_split=50)\n",
    "model.fit(fwd_feature_selector.transform(X_train), y_train)\n",
    "\n",
    "# Predict and evaluate on the transformed X_test\n",
    "y_pred = model.predict_proba(X_test_transformed)[:, 1]\n",
    "print(roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the original Test set\n",
    "TT = fwd_feature_selectorNB.transform(Test)\n",
    "\n",
    "hospital_death_prob = model.predict_proba(TT)\n",
    "# The predicted probabilities of each class are stored in the second column of the output array\n",
    "hospital_death = hospital_death_prob[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on the original Test set\n",
    "TT = fwd_feature_selector.transform(Test)\n",
    "\n",
    "hospital_death_prob = model.predict_proba(TT)\n",
    "# The predicted probabilities of each class are stored in the second column of the output array\n",
    "hospital_death = hospital_death_prob[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame(hospital_death, columns=['hospital_death'])\n",
    "\n",
    "# Add the record ID from the test data to the predictions DataFrame\n",
    "predictions_df.insert(0, 'RecordID', Test['RecordID'])\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictionsFWDSLEECTION.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'max_depth': [2, 4, 6, 8, 10], 'min_samples_split': [2, 5, 10, 20, 50]}\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit the grid search object on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters: \", best_params)\n",
    "print(\"Best score: \", best_score)\n",
    "\n",
    "# Fit the model on the transformed X_train using the best parameters\n",
    "model = DecisionTreeClassifier(max_depth=best_params['max_depth'], min_samples_split=best_params['min_samples_split'])\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the transformed X_test\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "print(roc_auc_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
